"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[638],{2076:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"module-1/chapter-1-3","title":"1.3 Sensors and Actuators","description":"Robots need eyes to see, ears to hear, and muscles to move. This chapter explores the sensors that enable robots to perceive their environment and the actuators that allow them to act upon it. These are the interface between the digital brain (AI) and the physical world.","source":"@site/docs/module-1/chapter-1-3.md","sourceDirName":"module-1","slug":"/module-1/chapter-1-3","permalink":"/physical-ai-humanoid-robotics-book/docs/module-1/chapter-1-3","draft":false,"unlisted":false,"editUrl":"https://github.com/billy-pk/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module-1/chapter-1-3.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"1.3 Sensors and Actuators"},"sidebar":"defaultSidebar","previous":{"title":"1.2 Robotics Fundamentals","permalink":"/physical-ai-humanoid-robotics-book/docs/module-1/chapter-1-2"},"next":{"title":"1.4 ROS and Simulation","permalink":"/physical-ai-humanoid-robotics-book/docs/module-1/chapter-1-4"}}');var r=s(4848),l=s(8453);const t={sidebar_position:3,title:"1.3 Sensors and Actuators"},o="Chapter 1.3: Sensors and Actuators",c={},a=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Sensors: Perceiving the World",id:"sensors-perceiving-the-world",level:2},{value:"Sensor Classification",id:"sensor-classification",level:3},{value:"Vision Sensors: Cameras",id:"vision-sensors-cameras",level:2},{value:"Camera Types",id:"camera-types",level:3},{value:"Camera Parameters",id:"camera-parameters",level:3},{value:"Example: Reading Camera in Python",id:"example-reading-camera-in-python",level:3},{value:"LIDAR: Laser Distance Measurement",id:"lidar-laser-distance-measurement",level:2},{value:"How LIDAR Works",id:"how-lidar-works",level:3},{value:"LIDAR Types",id:"lidar-types",level:3},{value:"LIDAR Specifications",id:"lidar-specifications",level:3},{value:"Applications in Humanoid Robots",id:"applications-in-humanoid-robots",level:3},{value:"IMU: Inertial Measurement Unit",id:"imu-inertial-measurement-unit",level:2},{value:"IMU Components",id:"imu-components",level:3},{value:"IMU Data Fusion",id:"imu-data-fusion",level:3},{value:"Humanoid Robot Applications",id:"humanoid-robot-applications",level:3},{value:"Force and Torque Sensors",id:"force-and-torque-sensors",level:2},{value:"Where They&#39;re Used",id:"where-theyre-used",level:3},{value:"Sensing Principles",id:"sensing-principles",level:3},{value:"6-Axis F/T Sensor",id:"6-axis-ft-sensor",level:3},{value:"Actuators: Making Robots Move",id:"actuators-making-robots-move",level:2},{value:"Actuator Comparison",id:"actuator-comparison",level:3},{value:"Electric Motors",id:"electric-motors",level:2},{value:"DC Motor (Brushed)",id:"dc-motor-brushed",level:3},{value:"Servo Motor",id:"servo-motor",level:3},{value:"Brushless DC Motor (BLDC)",id:"brushless-dc-motor-bldc",level:3},{value:"Hydraulic and Pneumatic Actuators",id:"hydraulic-and-pneumatic-actuators",level:2},{value:"Hydraulic Actuators",id:"hydraulic-actuators",level:3},{value:"Pneumatic Actuators",id:"pneumatic-actuators",level:3},{value:"Sensor Fusion: Combining Multiple Sensors",id:"sensor-fusion-combining-multiple-sensors",level:2},{value:"Why Sensor Fusion?",id:"why-sensor-fusion",level:3},{value:"Kalman Filter: The Classic Fusion Algorithm",id:"kalman-filter-the-classic-fusion-algorithm",level:3},{value:"Designing a Sensor Suite for Humanoid Robots",id:"designing-a-sensor-suite-for-humanoid-robots",level:2},{value:"Design Checklist",id:"design-checklist",level:3},{value:"Example: Warehouse Humanoid Robot",id:"example-warehouse-humanoid-robot",level:3},{value:"Exercises",id:"exercises",level:2},{value:"1. Sensor Selection",id:"1-sensor-selection",level:3},{value:"2. Camera Resolution Trade-off",id:"2-camera-resolution-trade-off",level:3},{value:"3. IMU Integration",id:"3-imu-integration",level:3},{value:"4. Motor Sizing",id:"4-motor-sizing",level:3},{value:"5. Code Challenge",id:"5-code-challenge",level:3},{value:"6. Sensor Fusion Design",id:"6-sensor-fusion-design",level:3},{value:"7. Research Task",id:"7-research-task",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"chapter-13-sensors-and-actuators",children:"Chapter 1.3: Sensors and Actuators"})}),"\n",(0,r.jsxs)(n.p,{children:["Robots need eyes to see, ears to hear, and muscles to move. This chapter explores the ",(0,r.jsx)(n.strong,{children:"sensors"})," that enable robots to perceive their environment and the ",(0,r.jsx)(n.strong,{children:"actuators"})," that allow them to act upon it. These are the interface between the digital brain (AI) and the physical world."]}),"\n",(0,r.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Classify"})," major sensor types: proprioceptive vs. exteroceptive"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Understand"})," how cameras, LIDAR, IMUs, and force sensors work"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Explain"})," actuator types: electric motors, hydraulics, pneumatics"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compare"})," sensor and actuator characteristics (range, accuracy, bandwidth)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Apply"})," sensor fusion concepts to combine multiple data sources"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Design"})," sensor/actuator systems for specific robotic applications"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"sensors-perceiving-the-world",children:"Sensors: Perceiving the World"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Sensors"})," convert physical phenomena (light, force, acceleration) into electrical signals that robots can process."]}),"\n",(0,r.jsx)(n.h3,{id:"sensor-classification",children:"Sensor Classification"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"1. Proprioceptive Sensors"})," (Internal State)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Measure robot's own configuration and motion"}),"\n",(0,r.jsx)(n.li,{children:"Examples: encoders, IMUs, force/torque sensors in joints"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"2. Exteroceptive Sensors"})," (External Environment)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Measure external world properties"}),"\n",(0,r.jsx)(n.li,{children:"Examples: cameras, LIDAR, microphones, tactile sensors"}),"\n"]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Sensor Type"}),(0,r.jsx)(n.th,{children:"Category"}),(0,r.jsx)(n.th,{children:"Measures"}),(0,r.jsx)(n.th,{children:"Typical Use"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Encoder"})}),(0,r.jsx)(n.td,{children:"Proprioceptive"}),(0,r.jsx)(n.td,{children:"Joint position/velocity"}),(0,r.jsx)(n.td,{children:"Motor control, odometry"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"IMU"})}),(0,r.jsx)(n.td,{children:"Proprioceptive"}),(0,r.jsx)(n.td,{children:"Acceleration, angular velocity"}),(0,r.jsx)(n.td,{children:"Balance, orientation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Camera"})}),(0,r.jsx)(n.td,{children:"Exteroceptive"}),(0,r.jsx)(n.td,{children:"Light intensity (RGB)"}),(0,r.jsx)(n.td,{children:"Object detection, navigation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"LIDAR"})}),(0,r.jsx)(n.td,{children:"Exteroceptive"}),(0,r.jsx)(n.td,{children:"Distance (time-of-flight)"}),(0,r.jsx)(n.td,{children:"3D mapping, obstacle avoidance"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Force/Torque"})}),(0,r.jsx)(n.td,{children:"Proprioceptive"}),(0,r.jsx)(n.td,{children:"Contact forces"}),(0,r.jsx)(n.td,{children:"Manipulation, collision detection"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Microphone"})}),(0,r.jsx)(n.td,{children:"Exteroceptive"}),(0,r.jsx)(n.td,{children:"Sound waves"}),(0,r.jsx)(n.td,{children:"Voice commands, audio localization"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"vision-sensors-cameras",children:"Vision Sensors: Cameras"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Cameras"})," are the most common sensors in robotics, providing rich visual information."]}),"\n",(0,r.jsx)(n.h3,{id:"camera-types",children:"Camera Types"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"1. RGB Cameras"})," (Standard Color)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Capture red, green, blue channels"}),"\n",(0,r.jsx)(n.li,{children:"Resolution: 640\xd7480 (VGA) to 4K+"}),"\n",(0,r.jsx)(n.li,{children:"Frame rate: 30-120 fps typical"}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pros"}),": Rich color info, inexpensive, mature algorithms"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cons"}),": No depth info, sensitive to lighting"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"2. Depth Cameras"})," (RGB-D)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Provide color + per-pixel distance"}),"\n",(0,r.jsxs)(n.li,{children:["Technologies:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Structured light"}),": Project pattern, measure distortion (Intel RealSense)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Time-of-flight (ToF)"}),": Measure light travel time (Microsoft Kinect)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Stereo"}),": Use two cameras like human eyes"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"3. Event Cameras"})," (DVS - Dynamic Vision Sensor)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Each pixel independently detects brightness changes"}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pros"}),": Ultra-low latency (<1ms), high dynamic range"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cons"}),": Novel technology, fewer algorithms available"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"camera-parameters",children:"Camera Parameters"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Intrinsic Parameters"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Focal length"})," (f): Distance from lens to sensor"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Principal point"})," (c\u2093, c\u1d67): Optical center in image"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lens distortion"}),": Radial and tangential distortion coefficients"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Camera Calibration"})," determines these parameters for accurate 3D reconstruction."]}),"\n",(0,r.jsx)(n.h3,{id:"example-reading-camera-in-python",children:"Example: Reading Camera in Python"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import cv2\n\n# Open camera (0 = default camera)\ncap = cv2.VideoCapture(0)\n\n# Set resolution\ncap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\ncap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n\nwhile True:\n    # Capture frame\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    # Convert to grayscale\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # Display\n    cv2.imshow('Robot Camera View', gray)\n\n    # Exit on 'q' key\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"lidar-laser-distance-measurement",children:"LIDAR: Laser Distance Measurement"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LIDAR"})," (Light Detection and Ranging) uses laser pulses to measure distances, creating precise 3D point clouds."]}),"\n",(0,r.jsx)(n.h3,{id:"how-lidar-works",children:"How LIDAR Works"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Emit"})," laser pulse"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Measure"})," time for reflection to return"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Calculate"})," distance: d = (c \xd7 t) / 2","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"c = speed of light (3\xd710\u2078 m/s)"}),"\n",(0,r.jsx)(n.li,{children:"t = round-trip time"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"lidar-types",children:"LIDAR Types"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"1D LIDAR"}),": Single beam (distance sensor)\n",(0,r.jsx)(n.strong,{children:"2D LIDAR"}),": Scanning in plane (e.g., Hokuyo, SICK) \u2014 common in mobile robots\n",(0,r.jsx)(n.strong,{children:"3D LIDAR"}),": Full 3D scanning (e.g., Velodyne, Ouster) \u2014 autonomous vehicles"]}),"\n",(0,r.jsx)(n.h3,{id:"lidar-specifications",children:"LIDAR Specifications"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Specification"}),(0,r.jsx)(n.th,{children:"Typical Range"}),(0,r.jsx)(n.th,{children:"Example"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Range"})}),(0,r.jsx)(n.td,{children:"0.1m - 100m"}),(0,r.jsx)(n.td,{children:"Indoor: 10m, Outdoor: 50m+"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Angular resolution"})}),(0,r.jsx)(n.td,{children:"0.1\xb0 - 1\xb0"}),(0,r.jsx)(n.td,{children:"Velodyne: 0.4\xb0 horizontal"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Scan rate"})}),(0,r.jsx)(n.td,{children:"5 - 20 Hz"}),(0,r.jsx)(n.td,{children:"10 Hz = 10 scans/second"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Accuracy"})}),(0,r.jsx)(n.td,{children:"\xb12cm - \xb15cm"}),(0,r.jsx)(n.td,{children:"High-end: \xb12cm"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"applications-in-humanoid-robots",children:"Applications in Humanoid Robots"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Navigation"}),": Avoid obstacles, map environment"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Localization"}),": Determine position in known map (SLAM)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Object detection"}),": Identify objects by shape"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Terrain analysis"}),": Detect stairs, slopes, uneven ground"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"imu-inertial-measurement-unit",children:"IMU: Inertial Measurement Unit"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"IMUs"})," measure acceleration and rotational velocity, crucial for balance and orientation."]}),"\n",(0,r.jsx)(n.h3,{id:"imu-components",children:"IMU Components"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"1. Accelerometer"})," (3-axis)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Measures linear acceleration in x, y, z"}),"\n",(0,r.jsx)(n.li,{children:"Detects gravity (when stationary)"}),"\n",(0,r.jsx)(n.li,{children:"Used for: orientation estimation, fall detection"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"2. Gyroscope"})," (3-axis)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Measures angular velocity (rotation rate)"}),"\n",(0,r.jsx)(n.li,{children:"Used for: orientation tracking, stabilization"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"3. Magnetometer"})," (3-axis, optional)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Measures magnetic field (compass)"}),"\n",(0,r.jsx)(n.li,{children:"Provides absolute heading (north reference)"}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Challenge"}),": Susceptible to magnetic interference"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"imu-data-fusion",children:"IMU Data Fusion"}),"\n",(0,r.jsxs)(n.p,{children:["Raw IMU data is noisy. ",(0,r.jsx)(n.strong,{children:"Sensor fusion"})," combines accelerometer and gyroscope:"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Complementary Filter"})," (simple approach):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import numpy as np\n\nclass ComplementaryFilter:\n    """\n    Fuse accelerometer and gyroscope for tilt angle estimation.\n    """\n    def __init__(self, alpha=0.98, dt=0.01):\n        """\n        Args:\n            alpha: Filter coefficient (0-1, higher = trust gyro more)\n            dt: Time step (seconds)\n        """\n        self.alpha = alpha\n        self.dt = dt\n        self.angle = 0.0  # Current estimated angle\n\n    def update(self, accel_angle, gyro_rate):\n        """\n        Update angle estimate.\n\n        Args:\n            accel_angle: Angle from accelerometer (degrees)\n            gyro_rate: Angular velocity from gyroscope (deg/s)\n\n        Returns:\n            Estimated angle (degrees)\n        """\n        # Integrate gyroscope (high-frequency, drifts over time)\n        gyro_angle = self.angle + gyro_rate * self.dt\n\n        # Combine with accelerometer (low-frequency, stable long-term)\n        self.angle = self.alpha * gyro_angle + (1 - self.alpha) * accel_angle\n\n        return self.angle\n\n# Example usage\nfilter = ComplementaryFilter(alpha=0.98, dt=0.01)\n\n# Simulate IMU readings\naccel_angle = 45.0  # Tilt from accelerometer\ngyro_rate = 2.0     # Rotating at 2 deg/s\n\nfor _ in range(100):\n    estimated_angle = filter.update(accel_angle, gyro_rate)\n    print(f"Estimated angle: {estimated_angle:.2f}\xb0")\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Advanced Fusion"}),": Kalman Filter, Madgwick Filter (quaternion-based)"]}),"\n",(0,r.jsx)(n.h3,{id:"humanoid-robot-applications",children:"Humanoid Robot Applications"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Balance control"}),": Detect tipping, adjust posture"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fall detection"}),": Trigger protective response"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Orientation estimation"}),': Know which way is "up"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gait analysis"}),": Monitor walking patterns"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"force-and-torque-sensors",children:"Force and Torque Sensors"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Force/Torque (F/T) sensors"})," measure contact forces, essential for manipulation and safe interaction."]}),"\n",(0,r.jsx)(n.h3,{id:"where-theyre-used",children:"Where They're Used"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Wrist"}),": Measure forces during grasping/manipulation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Feet"}),": Measure ground reaction forces (ZMP estimation)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Joints"}),": Detect collisions, measure load"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"sensing-principles",children:"Sensing Principles"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Strain Gauges"}),": Measure deformation of material under load\n",(0,r.jsx)(n.strong,{children:"Capacitive"}),": Measure capacitance change under pressure\n",(0,r.jsx)(n.strong,{children:"Piezoelectric"}),": Generate voltage when compressed"]}),"\n",(0,r.jsx)(n.h3,{id:"6-axis-ft-sensor",children:"6-Axis F/T Sensor"}),"\n",(0,r.jsx)(n.p,{children:"Measures:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Forces"}),": F\u2093, F\u1d67, Fz (3 axes)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Torques"}),": \u03c4\u2093, \u03c4\u1d67, \u03c4z (3 axes)"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Applications"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Example: Detect collision from force spike\ndef detect_collision(force_reading, threshold=50.0):\n    """\n    Detect collision based on force magnitude.\n\n    Args:\n        force_reading: (Fx, Fy, Fz) in Newtons\n        threshold: Force threshold for collision (N)\n\n    Returns:\n        True if collision detected\n    """\n    force_magnitude = np.linalg.norm(force_reading)\n    return force_magnitude > threshold\n\n# Simulated force reading\nforce = np.array([5.0, 10.0, 45.0])  # Mostly vertical\n\nif detect_collision(force, threshold=30.0):\n    print("Collision detected! Emergency stop.")\nelse:\n    print("Normal operation.")\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"actuators-making-robots-move",children:"Actuators: Making Robots Move"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Actuators"})," convert electrical energy into mechanical motion. The choice of actuator determines robot capabilities, cost, and complexity."]}),"\n",(0,r.jsx)(n.h3,{id:"actuator-comparison",children:"Actuator Comparison"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Power-to-Weight"}),(0,r.jsx)(n.th,{children:"Speed"}),(0,r.jsx)(n.th,{children:"Precision"}),(0,r.jsx)(n.th,{children:"Cost"}),(0,r.jsx)(n.th,{children:"Common Use"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"DC Motor"})}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"Low"}),(0,r.jsx)(n.td,{children:"Small robots, joints"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Servo Motor"})}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"Very High"}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"Precise positioning"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Stepper Motor"})}),(0,r.jsx)(n.td,{children:"Low"}),(0,r.jsx)(n.td,{children:"Low"}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"Low"}),(0,r.jsx)(n.td,{children:"3D printers, slow motion"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Brushless DC (BLDC)"})}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"Very High"}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"Drones, high-performance robots"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Hydraulic"})}),(0,r.jsx)(n.td,{children:"Very High"}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"Heavy-duty (construction, Atlas)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Pneumatic"})}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"Low"}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"Grippers, soft robotics"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"electric-motors",children:"Electric Motors"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Electric motors"})," are the most common actuators in humanoid robots."]}),"\n",(0,r.jsx)(n.h3,{id:"dc-motor-brushed",children:"DC Motor (Brushed)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Pros"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Simple to control (voltage \u2192 speed)"}),"\n",(0,r.jsx)(n.li,{children:"Inexpensive"}),"\n",(0,r.jsx)(n.li,{children:"Good torque-to-weight ratio"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Cons"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Brushes wear out over time"}),"\n",(0,r.jsx)(n.li,{children:"Less efficient than brushless"}),"\n",(0,r.jsx)(n.li,{children:"Electrical noise"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Control Example"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import RPi.GPIO as GPIO\n\nclass DCMotorController:\n    """\n    Simple DC motor controller using PWM.\n    """\n    def __init__(self, enable_pin, in1_pin, in2_pin):\n        GPIO.setmode(GPIO.BCM)\n        self.enable_pin = enable_pin\n        self.in1_pin = in1_pin\n        self.in2_pin = in2_pin\n\n        GPIO.setup(enable_pin, GPIO.OUT)\n        GPIO.setup(in1_pin, GPIO.OUT)\n        GPIO.setup(in2_pin, GPIO.OUT)\n\n        self.pwm = GPIO.PWM(enable_pin, 1000)  # 1kHz frequency\n        self.pwm.start(0)\n\n    def set_speed(self, speed):\n        """\n        Set motor speed.\n\n        Args:\n            speed: -100 to 100 (negative = reverse)\n        """\n        if speed > 0:\n            GPIO.output(self.in1_pin, GPIO.HIGH)\n            GPIO.output(self.in2_pin, GPIO.LOW)\n            self.pwm.ChangeDutyCycle(abs(speed))\n        elif speed < 0:\n            GPIO.output(self.in1_pin, GPIO.LOW)\n            GPIO.output(self.in2_pin, GPIO.HIGH)\n            self.pwm.ChangeDutyCycle(abs(speed))\n        else:\n            GPIO.output(self.in1_pin, GPIO.LOW)\n            GPIO.output(self.in2_pin, GPIO.LOW)\n            self.pwm.ChangeDutyCycle(0)\n\n    def stop(self):\n        self.set_speed(0)\n        self.pwm.stop()\n        GPIO.cleanup()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"servo-motor",children:"Servo Motor"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Servos"})," combine motor + encoder + controller for precise position control."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Types"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Standard servo"}),": Limited rotation (0-180\xb0)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Continuous rotation servo"}),": Full 360\xb0 rotation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Digital servo"}),": Faster response, more precise"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Control"}),": PWM signal encodes desired angle"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Pulse width: 1ms = 0\xb0, 1.5ms = 90\xb0, 2ms = 180\xb0\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example with Python"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import time\nimport pigpio  # Raspberry Pi GPIO library\n\nclass ServoController:\n    """\n    Control hobby servo motor (0-180\xb0).\n    """\n    def __init__(self, pin, min_pulse=500, max_pulse=2500):\n        self.pi = pigpio.pi()\n        self.pin = pin\n        self.min_pulse = min_pulse  # microseconds for 0\xb0\n        self.max_pulse = max_pulse  # microseconds for 180\xb0\n\n    def set_angle(self, angle):\n        """\n        Set servo angle.\n\n        Args:\n            angle: 0-180 degrees\n        """\n        angle = max(0, min(180, angle))  # Clamp to valid range\n        pulse_width = self.min_pulse + (angle / 180.0) * (self.max_pulse - self.min_pulse)\n        self.pi.set_servo_pulsewidth(self.pin, pulse_width)\n\n    def cleanup(self):\n        self.pi.set_servo_pulsewidth(self.pin, 0)\n        self.pi.stop()\n\n# Usage\nservo = ServoController(pin=18)\nservo.set_angle(90)  # Move to center\ntime.sleep(1)\nservo.set_angle(0)   # Move to 0\xb0\nservo.cleanup()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"brushless-dc-motor-bldc",children:"Brushless DC Motor (BLDC)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Advantages"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"High efficiency (85-90%)"}),"\n",(0,r.jsx)(n.li,{children:"Long lifespan (no brushes)"}),"\n",(0,r.jsx)(n.li,{children:"High power-to-weight ratio"}),"\n",(0,r.jsx)(n.li,{children:"Quiet operation"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Disadvantages"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Requires electronic speed controller (ESC)"}),"\n",(0,r.jsx)(n.li,{children:"More complex control (requires rotor position feedback)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Applications"}),": Quadcopters, high-performance humanoid joints"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"hydraulic-and-pneumatic-actuators",children:"Hydraulic and Pneumatic Actuators"}),"\n",(0,r.jsx)(n.h3,{id:"hydraulic-actuators",children:"Hydraulic Actuators"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Principle"}),": Pressurized fluid (oil) drives piston"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Pros"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Extremely high force (Boston Dynamics Atlas uses hydraulics)"}),"\n",(0,r.jsx)(n.li,{children:"High power density"}),"\n",(0,r.jsx)(n.li,{children:"Natural compliance (shock absorption)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Cons"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Heavy (pump, reservoir, valves)"}),"\n",(0,r.jsx)(n.li,{children:"Messy (oil leaks)"}),"\n",(0,r.jsx)(n.li,{children:"Complex maintenance"}),"\n",(0,r.jsx)(n.li,{children:"Expensive"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use cases"}),": Heavy-duty humanoids, construction robots"]}),"\n",(0,r.jsx)(n.h3,{id:"pneumatic-actuators",children:"Pneumatic Actuators"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Principle"}),": Compressed air drives piston or inflates chamber"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Pros"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Safe (air is compressible \u2192 inherent compliance)"}),"\n",(0,r.jsx)(n.li,{children:"Fast actuation"}),"\n",(0,r.jsx)(n.li,{children:"Clean (no fluids)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Cons"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Low precision (air compressibility)"}),"\n",(0,r.jsx)(n.li,{children:"Requires air compressor"}),"\n",(0,r.jsx)(n.li,{children:"Noisy"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use cases"}),": Grippers, soft robotics, prosthetics"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"sensor-fusion-combining-multiple-sensors",children:"Sensor Fusion: Combining Multiple Sensors"}),"\n",(0,r.jsxs)(n.p,{children:["No single sensor is perfect. ",(0,r.jsx)(n.strong,{children:"Sensor fusion"})," combines multiple sensors to overcome individual limitations."]}),"\n",(0,r.jsx)(n.h3,{id:"why-sensor-fusion",children:"Why Sensor Fusion?"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Sensor"}),(0,r.jsx)(n.th,{children:"Strengths"}),(0,r.jsx)(n.th,{children:"Weaknesses"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Camera"})}),(0,r.jsx)(n.td,{children:"Rich visual info, object recognition"}),(0,r.jsx)(n.td,{children:"No depth, lighting-dependent"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"LIDAR"})}),(0,r.jsx)(n.td,{children:"Accurate depth, works in dark"}),(0,r.jsx)(n.td,{children:"Expensive, no color/texture"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"IMU"})}),(0,r.jsx)(n.td,{children:"High-frequency orientation"}),(0,r.jsx)(n.td,{children:"Drifts over time"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"GPS"})}),(0,r.jsx)(n.td,{children:"Absolute position outdoors"}),(0,r.jsx)(n.td,{children:"Inaccurate indoors, slow updates"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Fusion examples"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Camera + LIDAR"}),": Color point clouds, semantic segmentation with depth"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"IMU + Encoder"}),": Accurate odometry (wheel slippage detection)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Camera + IMU"}),": Visual-inertial odometry (VIO) for drones"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"kalman-filter-the-classic-fusion-algorithm",children:"Kalman Filter: The Classic Fusion Algorithm"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Kalman filter"})," optimally combines noisy sensor measurements with predictions."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Concept"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Predict"})," next state using motion model"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Update"})," prediction with new sensor measurement"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Weight"})," prediction vs. measurement based on uncertainty"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example: Fusing GPS and IMU for position"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import numpy as np\n\nclass SimpleKalmanFilter:\n    """\n    1D Kalman filter for position estimation.\n    """\n    def __init__(self, process_variance, measurement_variance):\n        self.process_variance = process_variance  # Model uncertainty\n        self.measurement_variance = measurement_variance  # Sensor noise\n\n        self.position = 0.0\n        self.variance = 1.0\n\n    def predict(self, motion):\n        """\n        Predict next position based on motion.\n\n        Args:\n            motion: Expected movement (e.g., from IMU integration)\n        """\n        self.position += motion\n        self.variance += self.process_variance\n\n    def update(self, measurement):\n        """\n        Update estimate with new sensor measurement.\n\n        Args:\n            measurement: Sensor reading (e.g., from GPS)\n        """\n        # Kalman gain (how much to trust measurement vs. prediction)\n        kalman_gain = self.variance / (self.variance + self.measurement_variance)\n\n        # Update position\n        self.position += kalman_gain * (measurement - self.position)\n\n        # Update variance (uncertainty)\n        self.variance = (1 - kalman_gain) * self.variance\n\n    def get_state(self):\n        return self.position, self.variance\n\n# Example usage\nkf = SimpleKalmanFilter(process_variance=0.1, measurement_variance=1.0)\n\n# Simulate sensor readings\nfor t in range(10):\n    # IMU predicts 1m movement\n    kf.predict(motion=1.0)\n\n    # GPS measures position (with noise)\n    gps_reading = t + np.random.normal(0, 0.5)\n    kf.update(gps_reading)\n\n    pos, var = kf.get_state()\n    print(f"Time {t}: Position = {pos:.2f}m, Uncertainty = {var:.3f}")\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"designing-a-sensor-suite-for-humanoid-robots",children:"Designing a Sensor Suite for Humanoid Robots"}),"\n",(0,r.jsx)(n.p,{children:"When selecting sensors for a humanoid robot, consider:"}),"\n",(0,r.jsx)(n.h3,{id:"design-checklist",children:"Design Checklist"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"1. Task Requirements"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"What must the robot sense? (objects, terrain, humans)"}),"\n",(0,r.jsx)(n.li,{children:"Required range, accuracy, update rate?"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"2. Environmental Constraints"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Indoor vs. outdoor (lighting, weather)"}),"\n",(0,r.jsx)(n.li,{children:"Structured vs. unstructured environment"}),"\n",(0,r.jsx)(n.li,{children:"Presence of humans (safety sensors needed)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"3. Computational Resources"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Processing power for sensor data (cameras are data-heavy)"}),"\n",(0,r.jsx)(n.li,{children:"Real-time requirements (latency budgets)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"4. Cost and Power"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Budget constraints"}),"\n",(0,r.jsx)(n.li,{children:"Battery life impact"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"5. Redundancy"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Critical sensors should have backups"}),"\n",(0,r.jsx)(n.li,{children:"Diverse sensor modalities (don't rely on vision alone)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-warehouse-humanoid-robot",children:"Example: Warehouse Humanoid Robot"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Task"}),": Navigate warehouse, pick items, avoid humans"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Sensor Suite"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"2\xd7 RGB cameras"})," (stereo pair): Object recognition, depth estimation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"1\xd7 2D LIDAR"}),": Floor-level obstacle detection, navigation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"1\xd7 IMU"}),": Balance, orientation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"2\xd7 Force sensors"})," (wrists): Grasp feedback"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"4\xd7 Bumper switches"})," (body): Emergency collision detection"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"1\xd7 Microphone array"}),": Voice commands"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Rationale"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Stereo cameras: Sufficient for indoors, cheaper than LIDAR"}),"\n",(0,r.jsx)(n.li,{children:"2D LIDAR: Reliable navigation, lower cost than 3D"}),"\n",(0,r.jsx)(n.li,{children:"Force sensors: Essential for manipulation"}),"\n",(0,r.jsx)(n.li,{children:"Redundancy: Vision + LIDAR + bumpers for safety"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsx)(n.h3,{id:"1-sensor-selection",children:"1. Sensor Selection"}),"\n",(0,r.jsx)(n.p,{children:"For each scenario, select the most appropriate sensor and justify:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Detecting if a door is open or closed from 5m away"}),"\n",(0,r.jsx)(n.li,{children:"Measuring precise angle of robot's elbow joint"}),"\n",(0,r.jsx)(n.li,{children:"Detecting when robot's hand touches an object"}),"\n",(0,r.jsx)(n.li,{children:"Determining if robot is tilted (about to fall)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-camera-resolution-trade-off",children:"2. Camera Resolution Trade-off"}),"\n",(0,r.jsx)(n.p,{children:"A robot has limited processing power (can analyze 10 million pixels/second)."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Option A: 1280\xd7720 at 30 fps"}),"\n",(0,r.jsx)(n.li,{children:"Option B: 1920\xd71080 at 15 fps"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Which would you choose for:\na) Fast-moving object tracking\nb) Detailed object recognition\nc) Indoor navigation"}),"\n",(0,r.jsx)(n.h3,{id:"3-imu-integration",children:"3. IMU Integration"}),"\n",(0,r.jsx)(n.p,{children:"Given accelerometer reading: (0.5, 0.2, 9.6) m/s\xb2 when robot is stationary, calculate the tilt angle from vertical. (Hint: Gravity is 9.81 m/s\xb2)"}),"\n",(0,r.jsx)(n.h3,{id:"4-motor-sizing",children:"4. Motor Sizing"}),"\n",(0,r.jsx)(n.p,{children:"A robot arm link has:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Mass: 1.5 kg"}),"\n",(0,r.jsx)(n.li,{children:"Length: 0.4 m (center of mass at 0.2 m from joint)"}),"\n",(0,r.jsx)(n.li,{children:"Maximum angular acceleration: 10 rad/s\xb2"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Calculate the required motor torque (ignoring gravity for simplicity).\nFormula: \u03c4 = I\xb7\u03b1, where I = m\xb7r\xb2 for point mass"}),"\n",(0,r.jsx)(n.h3,{id:"5-code-challenge",children:"5. Code Challenge"}),"\n",(0,r.jsxs)(n.p,{children:["Implement a ",(0,r.jsx)(n.strong,{children:"median filter"})," to remove noise spikes from LIDAR data:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def median_filter(distances, window_size=5):\n    """\n    Apply median filter to distance measurements.\n\n    Args:\n        distances: List of distance readings\n        window_size: Size of median window (odd number)\n\n    Returns:\n        Filtered distances\n    """\n    # Your code here\n    pass\n'})}),"\n",(0,r.jsx)(n.h3,{id:"6-sensor-fusion-design",children:"6. Sensor Fusion Design"}),"\n",(0,r.jsx)(n.p,{children:"Design a sensor fusion scheme for estimating a humanoid robot's position in a building. You have:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"GPS (accurate outdoors, unreliable indoors)"}),"\n",(0,r.jsx)(n.li,{children:"IMU (high-frequency, drifts)"}),"\n",(0,r.jsx)(n.li,{children:"LIDAR (for localization via map matching)"}),"\n",(0,r.jsx)(n.li,{children:"Wheel encoders (measure distance traveled)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Describe which sensors to use in which situations and how to combine them."}),"\n",(0,r.jsx)(n.h3,{id:"7-research-task",children:"7. Research Task"}),"\n",(0,r.jsx)(n.p,{children:"Find specifications for a real humanoid robot (e.g., NAO, Pepper, Atlas, Optimus). List:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"All sensors it uses"}),"\n",(0,r.jsx)(n.li,{children:"All actuator types"}),"\n",(0,r.jsx)(n.li,{children:"Estimated cost (if available)"}),"\n",(0,r.jsx)(n.li,{children:"One limitation in its sensor/actuator design"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Proprioceptive sensors"})," measure internal state; ",(0,r.jsx)(n.strong,{children:"exteroceptive sensors"})," measure environment\n\u2705 ",(0,r.jsx)(n.strong,{children:"Cameras"})," provide rich visual data but lack depth; ",(0,r.jsx)(n.strong,{children:"LIDAR"})," provides accurate 3D geometry\n\u2705 ",(0,r.jsx)(n.strong,{children:"IMUs"})," are essential for balance and orientation in mobile robots\n\u2705 ",(0,r.jsx)(n.strong,{children:"Force sensors"})," enable safe, compliant manipulation\n\u2705 ",(0,r.jsx)(n.strong,{children:"Electric motors"})," (DC, servo, BLDC) are most common; ",(0,r.jsx)(n.strong,{children:"hydraulics"})," provide extreme power\n\u2705 ",(0,r.jsx)(n.strong,{children:"Sensor fusion"})," combines multiple sensors to overcome individual limitations\n\u2705 Sensor/actuator selection involves ",(0,r.jsx)(n.strong,{children:"task requirements, cost, power, and redundancy"})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Books"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Probabilistic Robotics"})," by Thrun, Burgard, Fox (sensor models, Kalman filtering)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Robotics: Modelling, Planning and Control"})," by Siciliano et al. (actuators, control)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Papers"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'"LIDAR-based 3D Object Perception" (survey of LIDAR processing)'}),"\n",(0,r.jsx)(n.li,{children:'"A Comparison of Kalman Filtering Approaches for Sensor Fusion" (fusion techniques)'}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Tutorials"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"OpenCV documentation (camera calibration, image processing)"}),"\n",(0,r.jsx)(n.li,{children:"ROS sensor integration tutorials (LIDAR, IMU, cameras)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Datasheets"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Intel RealSense D435 (depth camera)"}),"\n",(0,r.jsx)(n.li,{children:"Velodyne VLP-16 (3D LIDAR)"}),"\n",(0,r.jsx)(n.li,{children:"Bosch BMI088 (IMU)"}),"\n",(0,r.jsx)(n.li,{children:"Dynamixel servos (common in research robots)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Previous"}),": ",(0,r.jsx)(n.a,{href:"/physical-ai-humanoid-robotics-book/docs/module-1/chapter-1-2",children:"\u2190 Chapter 1.2: Robotics Fundamentals"})," | ",(0,r.jsx)(n.strong,{children:"Next"}),": ",(0,r.jsx)(n.a,{href:"/physical-ai-humanoid-robotics-book/docs/module-1/chapter-1-4",children:"Chapter 1.4: ROS and Simulation \u2192"})]}),"\n",(0,r.jsx)(n.p,{children:"With sensors and actuators understood, we're ready to learn the tools roboticists use to build and test systems: ROS and simulation!"})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>o});var i=s(6540);const r={},l=i.createContext(r);function t(e){const n=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(l.Provider,{value:n},e.children)}}}]);