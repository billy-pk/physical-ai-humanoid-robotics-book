"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[7484],{4441:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3/chapter-3-3","title":"3.3 Isaac ROS - Hardware-Accelerated VSLAM","description":"Visual SLAM (Simultaneous Localization and Mapping) enables humanoid robots to build maps and localize themselves using camera data. Isaac ROS provides GPU-accelerated VSLAM algorithms that run at real-time speeds\u2014essential for autonomous navigation in GPS-denied environments.","source":"@site/docs/module-3/chapter-3-3.md","sourceDirName":"module-3","slug":"/module-3/chapter-3-3","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3/chapter-3-3","draft":false,"unlisted":false,"editUrl":"https://github.com/billy-pk/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module-3/chapter-3-3.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"3.3 Isaac ROS - Hardware-Accelerated VSLAM"},"sidebar":"defaultSidebar","previous":{"title":"3.2 Synthetic Data Generation for Training","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3/chapter-3-2"},"next":{"title":"3.4 Nav2 Navigation for Bipedal Humanoids","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3/chapter-3-4"}}');var r=s(4848),a=s(8453);const t={sidebar_position:4,title:"3.3 Isaac ROS - Hardware-Accelerated VSLAM"},l="Chapter 3.3: Isaac ROS - Hardware-Accelerated VSLAM",o={},c=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Part 1: VSLAM Fundamentals",id:"part-1-vslam-fundamentals",level:2},{value:"What is VSLAM?",id:"what-is-vslam",level:3},{value:"VSLAM Pipeline",id:"vslam-pipeline",level:3},{value:"Isaac ROS VSLAM Packages",id:"isaac-ros-vslam-packages",level:3},{value:"Part 2: Hands-On Tutorial",id:"part-2-hands-on-tutorial",level:2},{value:"Project: Set Up Stereo VSLAM System",id:"project-set-up-stereo-vslam-system",level:3},{value:"Step 1: Install Isaac ROS Packages",id:"step-1-install-isaac-ros-packages",level:3},{value:"Step 2: Set Up Stereo Cameras",id:"step-2-set-up-stereo-cameras",level:3},{value:"Step 3: Configure Stereo Image Processing",id:"step-3-configure-stereo-image-processing",level:3},{value:"Step 4: Verify VSLAM Output",id:"step-4-verify-vslam-output",level:3},{value:"Step 5: Visualize in RViz2",id:"step-5-visualize-in-rviz2",level:3},{value:"Step 6: Integrate with Robot",id:"step-6-integrate-with-robot",level:3},{value:"Step 7: Debugging Common Issues",id:"step-7-debugging-common-issues",level:3},{value:"Issue 1: &quot;VSLAM status: LOST&quot;",id:"issue-1-vslam-status-lost",level:4},{value:"Issue 2: &quot;VSLAM not publishing odometry&quot;",id:"issue-2-vslam-not-publishing-odometry",level:4},{value:"Issue 3: &quot;Poor localization accuracy&quot;",id:"issue-3-poor-localization-accuracy",level:4},{value:"Issue 4: &quot;High CPU/GPU usage&quot;",id:"issue-4-high-cpugpu-usage",level:4},{value:"Part 3: Advanced Topics (Optional)",id:"part-3-advanced-topics-optional",level:2},{value:"IMU Integration",id:"imu-integration",level:3},{value:"Loop Closure Detection",id:"loop-closure-detection",level:3},{value:"Integration with Capstone",id:"integration-with-capstone",level:2},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Basic VSLAM Setup (Required)",id:"exercise-1-basic-vslam-setup-required",level:3},{value:"Exercise 2: VSLAM Accuracy Test (Required)",id:"exercise-2-vslam-accuracy-test-required",level:3},{value:"Exercise 3: IMU Integration (Challenge)",id:"exercise-3-imu-integration-challenge",level:3},{value:"Additional Resources",id:"additional-resources",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"chapter-33-isaac-ros---hardware-accelerated-vslam",children:"Chapter 3.3: Isaac ROS - Hardware-Accelerated VSLAM"})}),"\n",(0,r.jsx)(n.p,{children:"Visual SLAM (Simultaneous Localization and Mapping) enables humanoid robots to build maps and localize themselves using camera data. Isaac ROS provides GPU-accelerated VSLAM algorithms that run at real-time speeds\u2014essential for autonomous navigation in GPS-denied environments."}),"\n",(0,r.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Install"})," and configure Isaac ROS packages for VSLAM"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Set up"})," stereo VSLAM using GPU-accelerated algorithms"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Integrate"})," VSLAM with ROS 2 navigation stack"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Visualize"})," VSLAM output (maps, trajectories) in RViz2"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Debug"})," VSLAM performance and accuracy issues"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim"})," or ",(0,r.jsx)(n.strong,{children:"stereo cameras"})," (physical or simulated)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"NVIDIA GPU"})," with CUDA support (RTX 2060 or better)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS 2 Humble"})," configured"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Understanding"})," of SLAM concepts (mapping, localization, loop closure)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Basic computer vision"})," knowledge (features, descriptors, matching)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"part-1-vslam-fundamentals",children:"Part 1: VSLAM Fundamentals"}),"\n",(0,r.jsx)(n.h3,{id:"what-is-vslam",children:"What is VSLAM?"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"VSLAM (Visual SLAM)"})," uses camera images to:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Build maps"})," of the environment (3D structure)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Localize"})," the robot within the map (6DOF pose)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Track"})," camera motion in real-time"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Why VSLAM for humanoids?"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPS-denied"}),": Works indoors and in urban canyons"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Visual"}),": Uses cameras (cheaper than LiDAR)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Rich information"}),": Provides 3D structure for manipulation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time"}),": GPU acceleration enables real-time performance"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"vslam-pipeline",children:"VSLAM Pipeline"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Typical VSLAM pipeline"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Feature Detection"}),": Find keypoints (corners, edges) in images"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Feature Matching"}),": Match features between frames"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Motion Estimation"}),": Estimate camera pose from matches"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Map Building"}),": Add new 3D points to map"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loop Closure"}),": Detect revisited locations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimization"}),": Refine map and poses (bundle adjustment)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"isaac-ros-vslam-packages",children:"Isaac ROS VSLAM Packages"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Package"}),(0,r.jsx)(n.th,{children:"Function"}),(0,r.jsx)(n.th,{children:"GPU Acceleration"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_visual_slam"})}),(0,r.jsx)(n.td,{children:"Main VSLAM node"}),(0,r.jsx)(n.td,{children:"Yes (CUDA)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_stereo_image_proc"})}),(0,r.jsx)(n.td,{children:"Stereo rectification"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_image_proc"})}),(0,r.jsx)(n.td,{children:"Image preprocessing"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"isaac_ros_nitros"})}),(0,r.jsx)(n.td,{children:"Zero-copy messaging"}),(0,r.jsx)(n.td,{children:"Yes"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key advantage"}),": GPU acceleration enables real-time performance (30+ FPS)."]}),"\n",(0,r.jsx)(n.h2,{id:"part-2-hands-on-tutorial",children:"Part 2: Hands-On Tutorial"}),"\n",(0,r.jsx)(n.h3,{id:"project-set-up-stereo-vslam-system",children:"Project: Set Up Stereo VSLAM System"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Goal"}),": Configure Isaac ROS VSLAM with stereo cameras and visualize localization output."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Tools"}),": Isaac ROS, ROS 2 Humble, NVIDIA GPU, stereo cameras (or Isaac Sim)"]}),"\n",(0,r.jsx)(n.h3,{id:"step-1-install-isaac-ros-packages",children:"Step 1: Install Isaac ROS Packages"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Create workspace"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/isaac_ros_ws/src\ncd ~/isaac_ros_ws/src\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Clone Isaac ROS repositories"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Core packages\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_image_proc.git\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_stereo_image_proc.git\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git\n\n# Install dependencies\ncd ~/isaac_ros_ws\nrosdep update\nrosdep install --from-paths src --ignore-src -r -y\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Build workspace"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd ~/isaac_ros_ws\ncolcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release\nsource install/setup.bash\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Verify installation"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 pkg list | grep isaac\n# Should show: isaac_ros_visual_slam, isaac_ros_stereo_image_proc, etc.\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-2-set-up-stereo-cameras",children:"Step 2: Set Up Stereo Cameras"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Option A: Physical Stereo Camera"})," (e.g., Intel RealSense D435):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install RealSense ROS 2 driver\nsudo apt install ros-humble-realsense2-camera\n\n# Launch camera\nros2 launch realsense2_camera rs_launch.py\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Option B: Isaac Sim Stereo Cameras"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# In Isaac Sim Python script\nfrom omni.isaac.sensor import Camera\n\n# Left camera\nleft_camera = Camera(\n    prim_path="/World/LeftCamera",\n    position=[-0.05, 0, 1.6],  # Left eye\n    resolution=(1280, 720),\n    frequency=30\n)\n\n# Right camera\nright_camera = Camera(\n    prim_path="/World/RightCamera",\n    position=[0.05, 0, 1.6],  # Right eye\n    resolution=(1280, 720),\n    frequency=30\n)\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Verify stereo topics"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 topic list | grep camera\n# Should see:\n# /left/camera/image_raw\n# /right/camera/image_raw\n# /left/camera/camera_info\n# /right/camera/camera_info\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-3-configure-stereo-image-processing",children:"Step 3: Configure Stereo Image Processing"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Create launch file"}),": ",(0,r.jsx)(n.code,{children:"launch/stereo_vslam.launch.py"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nLaunch stereo VSLAM system\nROS 2 Humble | Isaac ROS\n\"\"\"\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # Stereo image proc (rectification)\n        Node(\n            package='isaac_ros_stereo_image_proc',\n            executable='isaac_ros_stereo_image_proc',\n            name='stereo_image_proc',\n            parameters=[{\n                'left_camera_namespace': '/left',\n                'right_camera_namespace': '/right',\n                'left_camera_name': 'camera',\n                'right_camera_name': 'camera',\n            }],\n            remappings=[\n                ('left/image_rect', '/left/image_rect'),\n                ('right/image_rect', '/right/image_rect'),\n                ('left/camera_info', '/left/camera_info'),\n                ('right/camera_info', '/right/camera_info'),\n            ]\n        ),\n        \n        # Visual SLAM node\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='isaac_ros_visual_slam',\n            name='visual_slam',\n            parameters=[{\n                'enable_rectified_pose': True,\n                'denoise_input_images': False,\n                'rectified_images': True,\n                'enable_imu': False,  # Set True if IMU available\n                'enable_slam_visualization': True,\n                'enable_landmarks_view': True,\n                'enable_observations_view': True,\n                'map_frame': 'map',\n                'odom_frame': 'odom',\n                'base_frame': 'base_link',\n                'input_left_camera_frame': 'left_camera_frame',\n                'input_right_camera_frame': 'right_camera_frame',\n            }],\n            remappings=[\n                ('stereo_camera/left/image', '/left/image_rect'),\n                ('stereo_camera/right/image', '/right/image_rect'),\n                ('stereo_camera/left/camera_info', '/left/camera_info'),\n                ('stereo_camera/right/camera_info', '/right/camera_info'),\n            ]\n        )\n    ])\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Launch"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"source ~/isaac_ros_ws/install/setup.bash\nros2 launch your_package stereo_vslam.launch.py\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-4-verify-vslam-output",children:"Step 4: Verify VSLAM Output"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Check VSLAM topics"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 topic list | grep vslam\n# Should see:\n# /visual_slam/tracking/odometry\n# /visual_slam/tracking/pose\n# /visual_slam/tracking/status\n# /visual_slam/map\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Echo odometry"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /visual_slam/tracking/odometry\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected Output"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"header:\n  stamp:\n    sec: 1234567890\n    nanosec: 123456789\n  frame_id: odom\nchild_frame_id: base_link\npose:\n  pose:\n    position:\n      x: 0.123\n      y: 0.456\n      z: 0.789\n    orientation:\n      x: 0.0\n      y: 0.0\n      z: 0.0\n      w: 1.0\ntwist:\n  linear:\n    x: 0.1\n    y: 0.0\n    z: 0.0\n  angular:\n    z: 0.05\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Check VSLAM status"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /visual_slam/tracking/status\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Status meanings"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TRACKING"}),": VSLAM is tracking successfully"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LOST"}),": Tracking lost (insufficient features)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"INITIALIZING"}),": Still initializing (first few frames)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"step-5-visualize-in-rviz2",children:"Step 5: Visualize in RViz2"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Launch RViz2"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rviz2\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Configure displays"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add TF"}),": Shows coordinate frames (map \u2192 odom \u2192 base_link)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add Odometry"}),": Topic ",(0,r.jsx)(n.code,{children:"/visual_slam/tracking/odometry"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add Map"}),": Topic ",(0,r.jsx)(n.code,{children:"/visual_slam/map"})," (if available)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add Camera"}),": Topic ",(0,r.jsx)(n.code,{children:"/left/image_rect"})," (for visual feedback)"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected visualization"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TF tree"}),": Shows robot pose in map frame"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Odometry arrow"}),": Shows robot position and orientation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Trajectory"}),": Path robot has traveled (if enabled)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"step-6-integrate-with-robot",children:"Step 6: Integrate with Robot"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Publish VSLAM pose to robot"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nBridge VSLAM pose to robot state\nROS 2 Humble | Python 3.10+\n"""\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Odometry\nfrom geometry_msgs.msg import TransformStamped\nimport tf2_ros\n\nclass VSLAMPoseBridge(Node):\n    def __init__(self):\n        super().__init__(\'vslam_pose_bridge\')\n        \n        # Subscribe to VSLAM odometry\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            \'/visual_slam/tracking/odometry\',\n            self.odom_callback,\n            10\n        )\n        \n        # Publish TF transform\n        self.tf_broadcaster = tf2_ros.TransformBroadcaster(self)\n        \n    def odom_callback(self, msg):\n        """Publish VSLAM pose as TF transform"""\n        t = TransformStamped()\n        t.header.stamp = self.get_clock().now().to_msg()\n        t.header.frame_id = \'map\'\n        t.child_frame_id = \'base_link\'\n        \n        t.transform.translation.x = msg.pose.pose.position.x\n        t.transform.translation.y = msg.pose.pose.position.y\n        t.transform.translation.z = msg.pose.pose.position.z\n        \n        t.transform.rotation = msg.pose.pose.orientation\n        \n        self.tf_broadcaster.sendTransform(t)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = VSLAMPoseBridge()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"step-7-debugging-common-issues",children:"Step 7: Debugging Common Issues"}),"\n",(0,r.jsx)(n.h4,{id:"issue-1-vslam-status-lost",children:'Issue 1: "VSLAM status: LOST"'}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": Tracking fails immediately or after few frames"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check camera topics are publishing\nros2 topic hz /left/image_rect\nros2 topic hz /right/image_rect\n\n# Verify camera info is correct\nros2 topic echo /left/camera_info\n\n# Check image quality (should have features)\nros2 run rqt_image_view rqt_image_view /left/image_rect\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Common causes"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Low texture"}),": Scene has no features (blank walls)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Motion blur"}),": Camera moving too fast"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Poor lighting"}),": Images too dark/bright"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Calibration"}),": Incorrect camera intrinsics"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"issue-2-vslam-not-publishing-odometry",children:'Issue 2: "VSLAM not publishing odometry"'}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": No ",(0,r.jsx)(n.code,{children:"/visual_slam/tracking/odometry"})," topic"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check node is running\nros2 node list | grep visual_slam\n\n# Check node logs\nros2 node info /visual_slam\n\n# Verify GPU is available\nnvidia-smi\n"})}),"\n",(0,r.jsx)(n.h4,{id:"issue-3-poor-localization-accuracy",children:'Issue 3: "Poor localization accuracy"'}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": Robot position drifts over time"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Increase feature detection\n# In launch file parameters:\n'enable_rectified_pose': True,\n'denoise_input_images': True,  # Enable denoising\n\n# Use IMU if available (reduces drift)\n'enable_imu': True,\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Calibration"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Stereo calibration"}),": Ensure cameras are properly calibrated"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Baseline"}),": Correct stereo baseline distance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Intrinsics"}),": Accurate camera matrix and distortion"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"issue-4-high-cpugpu-usage",children:'Issue 4: "High CPU/GPU usage"'}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": System lagging, high resource usage"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Reduce image resolution\n# In camera configuration:\nresolution=(640, 480)  # Instead of (1280, 720)\n\n# Reduce frame rate\nfrequency=15  # Instead of 30 Hz\n"})}),"\n",(0,r.jsx)(n.h2,{id:"part-3-advanced-topics-optional",children:"Part 3: Advanced Topics (Optional)"}),"\n",(0,r.jsx)(n.h3,{id:"imu-integration",children:"IMU Integration"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Add IMU to VSLAM"})," (reduces drift):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# In launch file\nNode(\n    package='isaac_ros_visual_slam',\n    executable='isaac_ros_visual_slam',\n    parameters=[{\n        'enable_imu': True,  # Enable IMU fusion\n    }],\n    remappings=[\n        # ... (camera topics)\n        ('imu', '/imu/data'),  # IMU topic\n    ]\n)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reduced drift"}),": IMU provides motion priors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Faster initialization"}),": IMU helps with initial motion"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Robustness"}),": Works better in low-texture environments"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"loop-closure-detection",children:"Loop Closure Detection"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Enable loop closure"})," (for map consistency):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"parameters=[{\n    'enable_loop_closure': True,\n    'loop_closure_search_radius': 5.0,  # meters\n    'loop_closure_min_inliers': 50,\n}]\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Map consistency"}),": Corrects accumulated drift"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Global optimization"}),": Refines entire map"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Relocalization"}),": Can relocalize after tracking loss"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"integration-with-capstone",children:"Integration with Capstone"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"How this chapter contributes"})," to the Week 13 autonomous humanoid:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Localization"}),": Capstone will use VSLAM for real-time pose estimation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Mapping"}),": Build maps of indoor environments for navigation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Robustness"}),": GPU acceleration enables real-time performance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Integration"}),": VSLAM provides pose for Nav2 navigation (Chapter 3.4)"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Understanding VSLAM now is essential for the capstone navigation system."}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(n.p,{children:"You learned:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 Installed ",(0,r.jsx)(n.strong,{children:"Isaac ROS packages"})," for VSLAM"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 Configured ",(0,r.jsx)(n.strong,{children:"stereo VSLAM"})," with GPU acceleration"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 Integrated ",(0,r.jsx)(n.strong,{children:"VSLAM with ROS 2"})," navigation stack"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 Visualized ",(0,r.jsx)(n.strong,{children:"VSLAM output"})," (odometry, maps) in RViz2"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 Debugged ",(0,r.jsx)(n.strong,{children:"VSLAM performance"})," and accuracy issues"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Next steps"}),": In Chapter 3.4, you'll configure Nav2 navigation stack for bipedal humanoid path planning."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsx)(n.h3,{id:"exercise-1-basic-vslam-setup-required",children:"Exercise 1: Basic VSLAM Setup (Required)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Objective"}),": Set up stereo VSLAM and verify tracking."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Install Isaac ROS packages"}),"\n",(0,r.jsx)(n.li,{children:"Configure stereo cameras (physical or simulated)"}),"\n",(0,r.jsx)(n.li,{children:"Launch VSLAM node"}),"\n",(0,r.jsx)(n.li,{children:"Verify odometry publishing"}),"\n",(0,r.jsx)(n.li,{children:"Visualize trajectory in RViz2"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Acceptance Criteria"}),":"]}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","VSLAM node running without errors"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Odometry topic publishing at 30+ Hz"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ",'Status shows "TRACKING"']}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Trajectory visible in RViz2"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Estimated Time"}),": 90 minutes"]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-2-vslam-accuracy-test-required",children:"Exercise 2: VSLAM Accuracy Test (Required)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Objective"}),": Measure VSLAM localization accuracy."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Move robot in known pattern (square, circle)"}),"\n",(0,r.jsx)(n.li,{children:"Record VSLAM odometry"}),"\n",(0,r.jsx)(n.li,{children:"Compare estimated path to ground truth"}),"\n",(0,r.jsx)(n.li,{children:"Calculate position error (RMSE)"}),"\n",(0,r.jsx)(n.li,{children:"Document accuracy results"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Metrics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Position error (meters)"}),"\n",(0,r.jsx)(n.li,{children:"Orientation error (degrees)"}),"\n",(0,r.jsx)(n.li,{children:"Drift rate (meters per minute)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Estimated Time"}),": 120 minutes"]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-3-imu-integration-challenge",children:"Exercise 3: IMU Integration (Challenge)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Objective"}),": Integrate IMU with VSLAM for improved accuracy."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Set up IMU sensor (physical or simulated)"}),"\n",(0,r.jsx)(n.li,{children:"Configure VSLAM to use IMU"}),"\n",(0,r.jsx)(n.li,{children:"Compare accuracy with/without IMU"}),"\n",(0,r.jsx)(n.li,{children:"Measure drift reduction"}),"\n",(0,r.jsx)(n.li,{children:"Document improvements"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["IMU publishing ",(0,r.jsx)(n.code,{children:"/imu/data"})," topic"]}),"\n",(0,r.jsxs)(n.li,{children:["VSLAM configured with ",(0,r.jsx)(n.code,{children:"enable_imu: True"})]}),"\n",(0,r.jsx)(n.li,{children:"Accuracy comparison report"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Estimated Time"}),": 180 minutes"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam",children:"Isaac ROS Visual SLAM"})," - GitHub repository"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://nvidia-isaac-ros.github.io/repositories_and_packages/isaac_ros_visual_slam/isaac_ros_visual_slam/",children:"VSLAM Documentation"})," - Official docs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.youtube.com/watch?v=U6vr3iNrwRA",children:"SLAM Tutorial"})," - Visual SLAM overview"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.opencv.org/4.x/dd/d53/tutorial_py_depthmap.html",children:"Stereo Vision"})," - Stereo depth estimation"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Next"}),": [Chapter 3.4: Nav2 Navigation for Bipedal Humanoids \u2192](chapter-3 to 4.md)"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var i=s(6540);const r={},a=i.createContext(r);function t(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);