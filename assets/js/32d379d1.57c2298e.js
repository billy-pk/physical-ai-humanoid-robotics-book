"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[9282],{4687:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3/chapter-3-5","title":"3.5 Sim-to-Real Transfer Workflows","description":"The ultimate test of simulation is deployment to physical hardware. Sim-to-real transfer validates that algorithms developed in Isaac Sim and Gazebo work on real robots. This chapter covers calibration, validation, and debugging the inevitable gaps between simulation and reality.","source":"@site/docs/module-3/chapter-3-5.md","sourceDirName":"module-3","slug":"/module-3/chapter-3-5","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3/chapter-3-5","draft":false,"unlisted":false,"editUrl":"https://github.com/billy-pk/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module-3/chapter-3-5.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"3.5 Sim-to-Real Transfer Workflows"},"sidebar":"defaultSidebar","previous":{"title":"3.4 Nav2 Navigation for Bipedal Humanoids","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3/chapter-3-4"},"next":{"title":"Module 4 Introduction","permalink":"/physical-ai-humanoid-robotics-book/docs/module-4/intro"}}');var a=s(4848),r=s(8453);const t={sidebar_position:6,title:"3.5 Sim-to-Real Transfer Workflows"},l="Chapter 3.5: Sim-to-Real Transfer Workflows",o={},c=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Part 1: Sim-to-Real Transfer Fundamentals",id:"part-1-sim-to-real-transfer-fundamentals",level:2},{value:"The Sim-to-Real Gap",id:"the-sim-to-real-gap",level:3},{value:"Transfer Strategies",id:"transfer-strategies",level:3},{value:"Part 2: Hands-On Tutorial",id:"part-2-hands-on-tutorial",level:2},{value:"Project: Validate Navigation on Physical Hardware",id:"project-validate-navigation-on-physical-hardware",level:3},{value:"Step 1: Pre-Deployment Checklist",id:"step-1-pre-deployment-checklist",level:3},{value:"Step 2: Sensor Calibration",id:"step-2-sensor-calibration",level:3},{value:"Step 3: Deploy to Hardware",id:"step-3-deploy-to-hardware",level:3},{value:"Step 4: Validate Navigation",id:"step-4-validate-navigation",level:3},{value:"Step 5: Debug Sim-to-Real Gaps",id:"step-5-debug-sim-to-real-gaps",level:3},{value:"Gap 1: VSLAM Tracking Lost",id:"gap-1-vslam-tracking-lost",level:4},{value:"Gap 2: Navigation Oscillations",id:"gap-2-navigation-oscillations",level:4},{value:"Gap 3: Costmap Inaccuracies",id:"gap-3-costmap-inaccuracies",level:4},{value:"Gap 4: Path Planning Failures",id:"gap-4-path-planning-failures",level:4},{value:"Step 6: Document Sim-to-Real Differences",id:"step-6-document-sim-to-real-differences",level:3},{value:"Part 3: Advanced Topics (Optional)",id:"part-3-advanced-topics-optional",level:2},{value:"Hybrid Simulation",id:"hybrid-simulation",level:3},{value:"Continuous Calibration",id:"continuous-calibration",level:3},{value:"Integration with Capstone",id:"integration-with-capstone",level:2},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Sensor Calibration (Required)",id:"exercise-1-sensor-calibration-required",level:3},{value:"Exercise 2: Navigation Validation (Required)",id:"exercise-2-navigation-validation-required",level:3},{value:"Exercise 3: Sim-to-Real Gap Analysis (Challenge)",id:"exercise-3-sim-to-real-gap-analysis-challenge",level:3},{value:"Additional Resources",id:"additional-resources",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"chapter-35-sim-to-real-transfer-workflows",children:"Chapter 3.5: Sim-to-Real Transfer Workflows"})}),"\n",(0,a.jsx)(n.p,{children:"The ultimate test of simulation is deployment to physical hardware. Sim-to-real transfer validates that algorithms developed in Isaac Sim and Gazebo work on real robots. This chapter covers calibration, validation, and debugging the inevitable gaps between simulation and reality."}),"\n",(0,a.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Validate"})," simulation algorithms on physical humanoid hardware"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Calibrate"})," sensors and actuators for real-world deployment"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Debug"})," sim-to-real gaps (lighting, friction, sensor noise)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Deploy"})," Isaac Sim-trained models to Unitree G1 or similar hardware"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Document"})," sim-to-real differences and mitigation strategies"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Completed Chapters 3.1 to 3.4"})," (Isaac Sim, VSLAM, Nav2)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Access to physical robot"})," (Unitree G1, Boston Dynamics Spot, or similar) - OR detailed simulation validation plan"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Understanding"})," of sensor calibration and system identification"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Basic hardware"})," debugging skills (multimeter, oscilloscope optional)"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"part-1-sim-to-real-transfer-fundamentals",children:"Part 1: Sim-to-Real Transfer Fundamentals"}),"\n",(0,a.jsx)(n.h3,{id:"the-sim-to-real-gap",children:"The Sim-to-Real Gap"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Why simulation differs from reality"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Physics"}),": Simplified models (friction, contact dynamics)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensors"}),": Perfect vs. noisy, calibrated vs. uncalibrated"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Actuators"}),": Ideal vs. real motors (backlash, saturation)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Environment"}),": Controlled vs. unpredictable (lighting, obstacles)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Timing"}),": Deterministic vs. variable latency"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Common gaps"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Lighting"}),": Simulation has perfect lighting, reality has shadows/glare"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Friction"}),": Simulation friction coefficients don't match real surfaces"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensor noise"}),": Simulation sensors are noiseless, real sensors have noise"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Actuator dynamics"}),": Simulation motors are ideal, real motors have delays"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Communication"}),": Simulation has no latency, real systems have network delays"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"transfer-strategies",children:"Transfer Strategies"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Strategy"}),(0,a.jsx)(n.th,{children:"Approach"}),(0,a.jsx)(n.th,{children:"Use Case"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Domain Randomization"})}),(0,a.jsx)(n.td,{children:"Vary simulation parameters"}),(0,a.jsx)(n.td,{children:"Robust models (Chapter 3.2)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Calibration"})}),(0,a.jsx)(n.td,{children:"Match sim to real parameters"}),(0,a.jsx)(n.td,{children:"Sensor/actuator tuning"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Progressive Transfer"})}),(0,a.jsx)(n.td,{children:"Start simple, add complexity"}),(0,a.jsx)(n.td,{children:"Incremental validation"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Hybrid Simulation"})}),(0,a.jsx)(n.td,{children:"Combine sim and real data"}),(0,a.jsx)(n.td,{children:"Best of both worlds"})]})]})]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"This chapter focuses on"}),": Calibration and progressive transfer."]}),"\n",(0,a.jsx)(n.h2,{id:"part-2-hands-on-tutorial",children:"Part 2: Hands-On Tutorial"}),"\n",(0,a.jsx)(n.h3,{id:"project-validate-navigation-on-physical-hardware",children:"Project: Validate Navigation on Physical Hardware"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Goal"}),": Deploy Nav2 navigation system (from Chapter 3.4) to physical humanoid and validate sim-to-real transfer."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Tools"}),": Physical robot (Unitree G1 or similar), ROS 2 Humble, Nav2, calibration tools"]}),"\n",(0,a.jsx)(n.h3,{id:"step-1-pre-deployment-checklist",children:"Step 1: Pre-Deployment Checklist"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simulation validation"}),":"]}),"\n",(0,a.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Navigation works in Isaac Sim/Gazebo"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","VSLAM provides accurate localization"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Path planning handles obstacles correctly"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Recovery behaviors work (spin, backup)"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","All ROS 2 topics publishing correctly"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Hardware preparation"}),":"]}),"\n",(0,a.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Robot fully charged"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Safety checks completed (emergency stop tested)"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Network connectivity verified"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","ROS 2 installed on robot computer"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Sensors calibrated (cameras, LiDAR, IMU)"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Environment preparation"}),":"]}),"\n",(0,a.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Test area cleared of obstacles"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Markers placed for ground truth validation"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Lighting conditions documented"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Safety personnel notified"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"step-2-sensor-calibration",children:"Step 2: Sensor Calibration"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Camera calibration"})," (for VSLAM):"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Install calibration tools\nsudo apt install ros-humble-camera-calibration\n\n# Calibrate stereo cameras\nros2 run camera_calibration cameracalibrator \\\n  --size 8x6 \\\n  --square 0.024 \\\n  left:=/left/image_raw right:=/right/image_raw \\\n  left_camera:=/left right_camera:=/right\n\n# Save calibration file\n# Copy to: ~/.ros/camera_info/left.yaml and right.yaml\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"LiDAR calibration"})," (for costmaps):"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Check LiDAR data\nros2 topic echo /scan\n\n# Verify range and angle limits match specification\n# Adjust in Nav2 costmap config if needed\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"IMU calibration"})," (for VSLAM fusion):"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nIMU calibration script\nROS 2 Humble | Python 3.10+\n"""\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Imu\nimport numpy as np\n\nclass IMUCalibrator(Node):\n    def __init__(self):\n        super().__init__(\'imu_calibrator\')\n        self.imu_sub = self.create_subscription(\n            Imu,\n            \'/imu/data\',\n            self.imu_callback,\n            10\n        )\n        self.accel_samples = []\n        self.gyro_samples = []\n        \n    def imu_callback(self, msg):\n        """Collect IMU samples for calibration"""\n        # Collect samples when robot is stationary\n        self.accel_samples.append([\n            msg.linear_acceleration.x,\n            msg.linear_acceleration.y,\n            msg.linear_acceleration.z\n        ])\n        self.gyro_samples.append([\n            msg.angular_velocity.x,\n            msg.angular_velocity.y,\n            msg.angular_velocity.z\n        ])\n        \n        if len(self.accel_samples) >= 1000:\n            self.calculate_bias()\n    \n    def calculate_bias(self):\n        """Calculate IMU bias (offset)"""\n        accel_bias = np.mean(self.accel_samples, axis=0)\n        gyro_bias = np.mean(self.gyro_samples, axis=0)\n        \n        # Expected: accel should be [0, 0, -9.81] when stationary (gravity)\n        # Expected: gyro should be [0, 0, 0] when stationary\n        \n        self.get_logger().info(f"Accelerometer bias: {accel_bias}")\n        self.get_logger().info(f"Gyroscope bias: {gyro_bias}")\n        \n        # Save to calibration file\n        # Apply bias correction in IMU driver\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IMUCalibrator()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-3-deploy-to-hardware",children:"Step 3: Deploy to Hardware"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Transfer code to robot"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Option 1: SSH to robot\nscp -r ~/isaac_ros_ws robot@robot-ip:~/isaac_ros_ws\n\n# Option 2: Git repository (recommended)\ngit push origin main\n# On robot: git pull\n\n# Option 3: ROS 2 package installation\n# Build debian packages and install on robot\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Launch on robot"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# SSH to robot\nssh robot@robot-ip\n\n# Source ROS 2\nsource /opt/ros/humble/setup.bash\nsource ~/isaac_ros_ws/install/setup.bash\n\n# Launch navigation\nros2 launch humanoid_nav2 humanoid_nav2.launch.py\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Verify topics"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# On robot or monitoring computer\nros2 topic list\n\n# Should see same topics as simulation:\n# /scan\n# /odom\n# /map\n# /plan\n# /cmd_vel\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-4-validate-navigation",children:"Step 4: Validate Navigation"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Test 1: Basic Navigation"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Set initial pose\nros2 topic pub --once /initialpose geometry_msgs/PoseWithCovarianceStamped \\\n  \"{header: {frame_id: 'map'}, pose: {pose: {position: {x: 0.0, y: 0.0, z: 0.0}, orientation: {w: 1.0}}}}\"\n\n# Send goal (1 meter forward)\nros2 action send_goal /navigate_to_pose nav2_msgs/action/NavigateToPose \\\n  \"{pose: {header: {frame_id: 'map'}, pose: {position: {x: 1.0, y: 0.0, z: 0.0}, orientation: {w: 1.0}}}\"\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Observe"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Does robot plan path correctly?"}),"\n",(0,a.jsx)(n.li,{children:"Does robot execute path smoothly?"}),"\n",(0,a.jsx)(n.li,{children:"Does robot reach goal within tolerance?"}),"\n",(0,a.jsx)(n.li,{children:"Any oscillations or stuck behavior?"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Test 2: Obstacle Avoidance"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Place obstacle in path\n# Send goal beyond obstacle\n# Verify robot avoids obstacle\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Test 3: Recovery Behaviors"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Place robot in corner (stuck situation)\n# Verify recovery behaviors activate (spin, backup)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-5-debug-sim-to-real-gaps",children:"Step 5: Debug Sim-to-Real Gaps"}),"\n",(0,a.jsx)(n.h4,{id:"gap-1-vslam-tracking-lost",children:"Gap 1: VSLAM Tracking Lost"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Symptoms"}),': VSLAM status shows "LOST" frequently']}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Causes"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Lighting"}),": Real lighting differs from simulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Texture"}),": Real surfaces have less texture"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Motion blur"}),": Real camera motion causes blur"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Increase feature detection threshold\n# In VSLAM config:\n'min_features': 100,  # Increase from default\n\n# Reduce motion blur\n# Slow down robot movement\nmax_vel_x: 0.3  # Instead of 0.5\n\n# Improve lighting\n# Add lights or use camera with better low-light performance\n"})}),"\n",(0,a.jsx)(n.h4,{id:"gap-2-navigation-oscillations",children:"Gap 2: Navigation Oscillations"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Symptoms"}),": Robot moves back and forth, doesn't reach goal"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Causes"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensor noise"}),": Real sensors noisier than simulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Actuator delays"}),": Real motors have response delays"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Friction"}),": Real friction differs from simulation"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# Increase goal tolerance\nxy_goal_tolerance: 0.5  # Larger tolerance\n\n# Reduce controller aggressiveness\nmax_vel_x: 0.3  # Slower\nacc_lim_x: 0.3  # Lower acceleration\n\n# Add filtering to sensor data\n# Filter LiDAR scans before costmap\n"})}),"\n",(0,a.jsx)(n.h4,{id:"gap-3-costmap-inaccuracies",children:"Gap 3: Costmap Inaccuracies"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Symptoms"}),": Costmap shows obstacles where none exist (or misses obstacles)"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Causes"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensor calibration"}),": Incorrect sensor parameters"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"TF errors"}),": Incorrect coordinate transforms"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Noise"}),": Sensor noise interpreted as obstacles"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Verify TF tree\nros2 run tf2_tools view_frames\n# Check: map \u2192 odom \u2192 base_link \u2192 sensor_frame\n\n# Recalibrate sensors\n# Run calibration procedures\n\n# Adjust costmap parameters\nobstacle_max_range: 3.0  # Reduce range to minimize noise\ninflation_radius: 0.6    # Increase safety margin\n"})}),"\n",(0,a.jsx)(n.h4,{id:"gap-4-path-planning-failures",children:"Gap 4: Path Planning Failures"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Symptoms"}),': "No path found" errors on real robot']}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Causes"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Map differences"}),": Real environment differs from simulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Costmap inflation"}),": Too conservative (blocks all paths)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Goal placement"}),": Goal in obstacle or unreachable"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# Reduce inflation radius\ninflation_radius: 0.4  # Smaller safety margin\n\n# Allow unknown space\nallow_unknown: true\n\n# Increase goal tolerance\ntolerance: 1.0  # Larger tolerance\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-6-document-sim-to-real-differences",children:"Step 6: Document Sim-to-Real Differences"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Create validation report"}),": ",(0,a.jsx)(n.code,{children:"docs/sim_to_real_validation.md"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-markdown",children:"# Sim-to-Real Validation Report\n\n## Test Environment\n- **Robot**: Unitree G1\n- **Date**: 2024-XX-XX\n- **Location**: Test lab\n- **Lighting**: Fluorescent (500 lux)\n\n## Test Results\n\n### Navigation Accuracy\n| Metric | Simulation | Real Hardware | Gap |\n|--------|------------|---------------|-----|\n| Position Error (RMSE) | 0.05 m | 0.15 m | +0.10 m |\n| Goal Success Rate | 100% | 85% | -15% |\n| Path Smoothness | 2.3 turns/m | 3.1 turns/m | +0.8 turns/m |\n\n### VSLAM Performance\n| Metric | Simulation | Real Hardware | Gap |\n|--------|------------|---------------|-----|\n| Tracking Success | 100% | 75% | -25% |\n| Localization Error | 0.02 m | 0.08 m | +0.06 m |\n| Frame Rate | 30 FPS | 25 FPS | -5 FPS |\n\n## Identified Gaps\n\n### 1. Lighting Differences\n**Issue**: Real lighting causes VSLAM tracking loss\n**Impact**: High (frequent re-initialization)\n**Mitigation**: Added lighting, improved camera settings\n\n### 2. Sensor Noise\n**Issue**: Real sensors noisier than simulation\n**Impact**: Medium (costmap inaccuracies)\n**Mitigation**: Added filtering, increased inflation radius\n\n### 3. Friction Differences\n**Issue**: Real friction lower than simulation\n**Impact**: Low (slight path deviations)\n**Mitigation**: Adjusted velocity limits\n\n## Recommendations\n\n1. **Improve lighting** in test environment\n2. **Add sensor filtering** to reduce noise\n3. **Increase goal tolerance** for robustness\n4. **Test in multiple environments** (indoor, outdoor, different lighting)\n\n## Next Steps\n\n- [ ] Deploy to production environment\n- [ ] Long-term testing (100+ navigation runs)\n- [ ] Performance monitoring\n- [ ] Continuous calibration updates\n"})}),"\n",(0,a.jsx)(n.h2,{id:"part-3-advanced-topics-optional",children:"Part 3: Advanced Topics (Optional)"}),"\n",(0,a.jsx)(n.h3,{id:"hybrid-simulation",children:"Hybrid Simulation"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Combine sim and real data"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Use real sensor data in simulation\n# Replace simulated camera with real camera feed\n# Keep physics simulation, use real perception\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Real sensor data (no sim-to-real gap for perception)"}),"\n",(0,a.jsx)(n.li,{children:"Safe physics testing (no hardware damage)"}),"\n",(0,a.jsx)(n.li,{children:"Faster iteration (no need to reset real robot)"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"continuous-calibration",children:"Continuous Calibration"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Auto-calibration system"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Monitor sensor drift over time\n# Automatically recalibrate when drift detected\n# Update calibration parameters dynamically\n"})}),"\n",(0,a.jsx)(n.h2,{id:"integration-with-capstone",children:"Integration with Capstone"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"How this chapter contributes"})," to the Week 13 autonomous humanoid:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Validation"}),": Capstone algorithms validated on physical hardware"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Calibration"}),": Sensors and actuators calibrated for real-world"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Documentation"}),": Sim-to-real gaps documented and mitigated"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Deployment"}),": Ready for production deployment"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Understanding sim-to-real transfer now ensures the capstone works on real hardware."}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"You learned:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\u2705 Validated ",(0,a.jsx)(n.strong,{children:"simulation algorithms"})," on physical hardware"]}),"\n",(0,a.jsxs)(n.li,{children:["\u2705 Calibrated ",(0,a.jsx)(n.strong,{children:"sensors and actuators"})," for real-world deployment"]}),"\n",(0,a.jsxs)(n.li,{children:["\u2705 Debugged ",(0,a.jsx)(n.strong,{children:"sim-to-real gaps"})," (lighting, friction, sensor noise)"]}),"\n",(0,a.jsxs)(n.li,{children:["\u2705 Deployed ",(0,a.jsx)(n.strong,{children:"Isaac Sim-trained models"})," to physical robot"]}),"\n",(0,a.jsxs)(n.li,{children:["\u2705 Documented ",(0,a.jsx)(n.strong,{children:"sim-to-real differences"})," and mitigation strategies"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Next steps"}),": Module 4 (Vision-Language-Action) will integrate voice commands, LLM planning, and multi-modal interaction for the final capstone project."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,a.jsx)(n.h3,{id:"exercise-1-sensor-calibration-required",children:"Exercise 1: Sensor Calibration (Required)"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Objective"}),": Calibrate sensors for real-world deployment."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Calibrate stereo cameras (if available)"}),"\n",(0,a.jsx)(n.li,{children:"Calibrate IMU (measure bias)"}),"\n",(0,a.jsx)(n.li,{children:"Verify LiDAR data quality"}),"\n",(0,a.jsx)(n.li,{children:"Document calibration parameters"}),"\n",(0,a.jsx)(n.li,{children:"Compare calibrated vs. uncalibrated performance"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Acceptance Criteria"}),":"]}),"\n",(0,a.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Camera calibration file created"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","IMU bias measured and documented"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Sensor data quality verified"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Calibration report created"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Estimated Time"}),": 120 minutes"]}),"\n",(0,a.jsx)(n.h3,{id:"exercise-2-navigation-validation-required",children:"Exercise 2: Navigation Validation (Required)"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Objective"}),": Test Nav2 navigation on physical hardware (or detailed simulation plan)."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Deploy Nav2 to robot (or create deployment plan)"}),"\n",(0,a.jsx)(n.li,{children:"Test basic navigation (forward, backward, turn)"}),"\n",(0,a.jsx)(n.li,{children:"Test obstacle avoidance"}),"\n",(0,a.jsx)(n.li,{children:"Measure navigation accuracy"}),"\n",(0,a.jsx)(n.li,{children:"Document sim-to-real differences"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"If no hardware available"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Create detailed deployment plan"}),"\n",(0,a.jsx)(n.li,{children:"Document expected sim-to-real gaps"}),"\n",(0,a.jsx)(n.li,{children:"Propose mitigation strategies"}),"\n",(0,a.jsx)(n.li,{children:"Create validation test procedures"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Acceptance Criteria"}),":"]}),"\n",(0,a.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Navigation tested (or plan created)"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Accuracy metrics documented"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Sim-to-real gaps identified"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Mitigation strategies proposed"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Estimated Time"}),": 180 minutes"]}),"\n",(0,a.jsx)(n.h3,{id:"exercise-3-sim-to-real-gap-analysis-challenge",children:"Exercise 3: Sim-to-Real Gap Analysis (Challenge)"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Objective"}),": Comprehensive analysis of simulation vs. reality differences."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Run identical tests in simulation and real hardware"}),"\n",(0,a.jsx)(n.li,{children:"Measure quantitative differences (position error, success rate)"}),"\n",(0,a.jsx)(n.li,{children:"Identify qualitative differences (behavior, appearance)"}),"\n",(0,a.jsx)(n.li,{children:"Propose improvements to simulation models"}),"\n",(0,a.jsx)(n.li,{children:"Create comprehensive validation report"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Metrics"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Position accuracy (RMSE)"}),"\n",(0,a.jsx)(n.li,{children:"Success rate (%)"}),"\n",(0,a.jsx)(n.li,{children:"Path smoothness"}),"\n",(0,a.jsx)(n.li,{children:"Computation time"}),"\n",(0,a.jsx)(n.li,{children:"Resource usage"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Estimated Time"}),": 240 minutes"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"http://wiki.ros.org/calibration",children:"ROS 2 Robot Calibration"})," - Calibration tools"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://arxiv.org/abs/1703.06907",children:"Sim-to-Real Transfer"})," - Research paper"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://www.unitree.com/",children:"Unitree G1 Documentation"})," - Hardware specifications"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://dev.bostondynamics.com/",children:"Boston Dynamics Spot SDK"})," - Example deployment"]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Next"}),": ",(0,a.jsx)(n.a,{href:"/physical-ai-humanoid-robotics-book/docs/module-4/intro",children:"Module 4: Vision-Language-Action (VLA) \u2192"})]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var i=s(6540);const a={},r=i.createContext(a);function t(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);