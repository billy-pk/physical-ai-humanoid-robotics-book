"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[1643],{7966:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>c,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"module-4/chapter-4-3","title":"4.3 Natural Language to ROS 2 Actions","description":"LLM-generated plans must be executed by the robot. This chapter covers mapping natural language actions to ROS 2 Action goals, implementing action executors, handling preconditions and postconditions, and creating feedback mechanisms for robust task execution.","source":"@site/docs/module-4/chapter-4-3.md","sourceDirName":"module-4","slug":"/module-4/chapter-4-3","permalink":"/physical-ai-humanoid-robotics-book/docs/module-4/chapter-4-3","draft":false,"unlisted":false,"editUrl":"https://github.com/billy-pk/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module-4/chapter-4-3.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"4.3 Natural Language to ROS 2 Actions"},"sidebar":"defaultSidebar","previous":{"title":"4.2 LLM-Based Cognitive Planning","permalink":"/physical-ai-humanoid-robotics-book/docs/module-4/chapter-4-2"},"next":{"title":"4.4 Multi-Modal Integration (Speech + Vision + Gesture)","permalink":"/physical-ai-humanoid-robotics-book/docs/module-4/chapter-4-4"}}');var s=t(4848),o=t(8453);const a={sidebar_position:4,title:"4.3 Natural Language to ROS 2 Actions"},c="Chapter 4.3: Natural Language to ROS 2 Actions",r={},l=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Part 1: Action Mapping Fundamentals",id:"part-1-action-mapping-fundamentals",level:2},{value:"Natural Language \u2192 ROS 2 Actions",id:"natural-language--ros-2-actions",level:3},{value:"ROS 2 Action Types",id:"ros-2-action-types",level:3},{value:"Action Execution Flow",id:"action-execution-flow",level:3},{value:"Part 2: Hands-On Tutorial",id:"part-2-hands-on-tutorial",level:2},{value:"Project: Action Executor for Humanoid Robot",id:"project-action-executor-for-humanoid-robot",level:3},{value:"Step 1: Define Custom Actions",id:"step-1-define-custom-actions",level:3},{value:"Step 2: Create Action Executor Node",id:"step-2-create-action-executor-node",level:3},{value:"Step 3: Test Action Execution",id:"step-3-test-action-execution",level:3},{value:"Step 4: Precondition Checking",id:"step-4-precondition-checking",level:3},{value:"Step 5: Debugging Common Issues",id:"step-5-debugging-common-issues",level:3},{value:"Issue 1: &quot;Action server not available&quot;",id:"issue-1-action-server-not-available",level:4},{value:"Issue 2: &quot;Action goal rejected&quot;",id:"issue-2-action-goal-rejected",level:4},{value:"Issue 3: &quot;Action execution hangs&quot;",id:"issue-3-action-execution-hangs",level:4},{value:"Issue 4: &quot;Actions execute out of order&quot;",id:"issue-4-actions-execute-out-of-order",level:4},{value:"Part 3: Advanced Topics (Optional)",id:"part-3-advanced-topics-optional",level:2},{value:"Parallel Action Execution",id:"parallel-action-execution",level:3},{value:"Action Retry Logic",id:"action-retry-logic",level:3},{value:"Integration with Capstone",id:"integration-with-capstone",level:2},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Basic Action Execution (Required)",id:"exercise-1-basic-action-execution-required",level:3},{value:"Exercise 2: Precondition Checking (Required)",id:"exercise-2-precondition-checking-required",level:3},{value:"Exercise 3: Error Recovery (Challenge)",id:"exercise-3-error-recovery-challenge",level:3},{value:"Additional Resources",id:"additional-resources",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-43-natural-language-to-ros-2-actions",children:"Chapter 4.3: Natural Language to ROS 2 Actions"})}),"\n",(0,s.jsx)(n.p,{children:"LLM-generated plans must be executed by the robot. This chapter covers mapping natural language actions to ROS 2 Action goals, implementing action executors, handling preconditions and postconditions, and creating feedback mechanisms for robust task execution."}),"\n",(0,s.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Map"})," natural language actions to ROS 2 Action goals"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Implement"})," action executor coordinating multiple behaviors"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Handle"})," action preconditions and postconditions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Create"})," feedback mechanisms for action completion"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Debug"})," action execution failures and recovery"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Chapter 4.2"})," completed (LLM planning)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ROS 2 Actions"})," understanding (Module 1, Chapter 1.1)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ROS 2 Humble"})," configured"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Python 3.10+"})," with rclpy experience"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Understanding"})," of state machines and action coordination"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"part-1-action-mapping-fundamentals",children:"Part 1: Action Mapping Fundamentals"}),"\n",(0,s.jsx)(n.h3,{id:"natural-language--ros-2-actions",children:"Natural Language \u2192 ROS 2 Actions"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mapping challenge"}),': LLM generates abstract actions ("pick_up", "navigate_to"), but ROS 2 Actions require specific goals (coordinates, object IDs, poses).']}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mapping strategies"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Direct mapping"}),": Simple actions map directly (stop \u2192 emergency stop action)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter extraction"}),": Extract parameters from LLM output (location \u2192 coordinates)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Query resolution"}),': Resolve ambiguous references ("the cup" \u2192 object ID via vision)']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Precondition checking"}),": Verify action can execute (object exists, robot can reach)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"ros-2-action-types",children:"ROS 2 Action Types"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Action Type"}),(0,s.jsx)(n.th,{children:"Use Case"}),(0,s.jsx)(n.th,{children:"Example"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"NavigateToPose"})}),(0,s.jsx)(n.td,{children:"Navigation"}),(0,s.jsx)(n.td,{children:"Move to (x, y, theta)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FollowPath"})}),(0,s.jsx)(n.td,{children:"Path following"}),(0,s.jsx)(n.td,{children:"Follow planned path"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"PickObject"})}),(0,s.jsx)(n.td,{children:"Manipulation"}),(0,s.jsx)(n.td,{children:"Grasp object at pose"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"PlaceObject"})}),(0,s.jsx)(n.td,{children:"Manipulation"}),(0,s.jsx)(n.td,{children:"Place object at pose"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"LookAt"})}),(0,s.jsx)(n.td,{children:"Perception"}),(0,s.jsx)(n.td,{children:"Point camera at target"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Speak"})}),(0,s.jsx)(n.td,{children:"Communication"}),(0,s.jsx)(n.td,{children:"Text-to-speech output"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Custom actions"}),": Define your own for robot-specific behaviors."]}),"\n",(0,s.jsx)(n.h3,{id:"action-execution-flow",children:"Action Execution Flow"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Typical flow"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Receive plan"}),": JSON array of actions from LLM"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Validate preconditions"}),": Check if action can execute"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Map to ROS 2 Action"}),": Convert abstract action \u2192 Action goal"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Send goal"}),": Call ROS 2 Action client"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Monitor execution"}),": Track progress and handle feedback"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Check postconditions"}),": Verify action completed successfully"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Handle errors"}),": Replan if action fails"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"part-2-hands-on-tutorial",children:"Part 2: Hands-On Tutorial"}),"\n",(0,s.jsx)(n.h3,{id:"project-action-executor-for-humanoid-robot",children:"Project: Action Executor for Humanoid Robot"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Goal"}),": Create action executor that takes LLM-generated plans and executes them via ROS 2 Actions."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Tools"}),": ROS 2 Humble, rclpy, action clients, Python 3.10+"]}),"\n",(0,s.jsx)(n.h3,{id:"step-1-define-custom-actions",children:"Step 1: Define Custom Actions"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Create action package"}),": ",(0,s.jsx)(n.code,{children:"humanoid_actions"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cd ~/isaac_ros_ws/src\nros2 pkg create --build-type ament_cmake humanoid_actions --dependencies rclcpp action_msgs geometry_msgs\ncd humanoid_actions\nmkdir action\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Define PickObject action"}),": ",(0,s.jsx)(n.code,{children:"action/PickObject.action"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"# Goal: Object to pick up\nstring object_id\ngeometry_msgs/PoseStamped object_pose\n\n---\n# Result: Success status\nbool success\nstring message\n\n---\n# Feedback: Current status\nstring status\nfloat32 progress  # 0.0 to 1.0\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Define PlaceObject action"}),": ",(0,s.jsx)(n.code,{children:"action/PlaceObject.action"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"# Goal: Where to place object\nstring object_id\ngeometry_msgs/PoseStamped target_pose\n\n---\n# Result\nbool success\nstring message\n\n---\n# Feedback\nstring status\nfloat32 progress\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsxs)(n.strong,{children:["Update ",(0,s.jsx)(n.code,{children:"CMakeLists.txt"})]}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cmake",children:'find_package(rosidl_default_generators REQUIRED)\n\nrosidl_generate_interfaces(${PROJECT_NAME}\n  "action/PickObject.action"\n  "action/PlaceObject.action"\n  DEPENDENCIES geometry_msgs action_msgs\n)\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Build actions"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cd ~/isaac_ros_ws\ncolcon build --packages-select humanoid_actions\nsource install/setup.bash\n"})}),"\n",(0,s.jsx)(n.h3,{id:"step-2-create-action-executor-node",children:"Step 2: Create Action Executor Node"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Create executor"}),": ",(0,s.jsx)(n.code,{children:"voice_commands/action_executor.py"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nAction executor for humanoid robot\nExecutes LLM-generated plans via ROS 2 Actions\nROS 2 Humble | Python 3.10+\n"""\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.action import ActionClient\nfrom std_msgs.msg import String\nfrom nav2_msgs.action import NavigateToPose\nfrom geometry_msgs.msg import PoseStamped, Pose, Point, Quaternion\nimport json\nimport math\n\n# Import custom actions (after building)\ntry:\n    from humanoid_actions.action import PickObject, PlaceObject\n    CUSTOM_ACTIONS_AVAILABLE = True\nexcept ImportError:\n    CUSTOM_ACTIONS_AVAILABLE = False\n    print("Warning: Custom actions not available, using placeholders")\n\nclass ActionExecutor(Node):\n    """\n    Executes LLM-generated action plans via ROS 2 Actions\n    """\n    def __init__(self):\n        super().__init__(\'action_executor\')\n        \n        # Subscribe to plans\n        self.plan_sub = self.create_subscription(\n            String,\n            \'/voice_commands/plan\',\n            self.plan_callback,\n            10\n        )\n        \n        # Publishers for status\n        self.status_pub = self.create_publisher(String, \'/voice_commands/execution_status\', 10)\n        self.complete_pub = self.create_publisher(String, \'/voice_commands/action_complete\', 10)\n        self.error_pub = self.create_publisher(String, \'/voice_commands/action_error\', 10)\n        \n        # Action clients\n        self.nav_client = ActionClient(self, NavigateToPose, \'navigate_to_pose\')\n        \n        if CUSTOM_ACTIONS_AVAILABLE:\n            self.pick_client = ActionClient(self, PickObject, \'pick_object\')\n            self.place_client = ActionClient(self, PlaceObject, \'place_object\')\n        \n        # Execution state\n        self.current_plan = []\n        self.current_action_index = 0\n        self.executing = False\n        \n        # Location mapping (simplified - would use VSLAM/vision in production)\n        self.location_map = {\n            "kitchen": {"x": 3.0, "y": 2.0, "theta": 0.0},\n            "living_room": {"x": 0.0, "y": 0.0, "theta": 0.0},\n            "table": {"x": 2.0, "y": 1.0, "theta": 0.0},\n            "shelf": {"x": 1.0, "y": 3.0, "theta": 1.57},\n        }\n        \n        self.get_logger().info(\'Action executor started\')\n    \n    def plan_callback(self, msg):\n        """Receive plan and start execution"""\n        try:\n            plan = json.loads(msg.data)\n            if isinstance(plan, list) and len(plan) > 0:\n                self.current_plan = plan\n                self.current_action_index = 0\n                self.executing = True\n                self.get_logger().info(f\'Received plan with {len(plan)} actions\')\n                self.execute_next_action()\n            else:\n                self.get_logger().error(\'Invalid plan format\')\n        except json.JSONDecodeError as e:\n            self.get_logger().error(f\'Failed to parse plan: {e}\')\n    \n    def execute_next_action(self):\n        """Execute next action in plan"""\n        if not self.executing or self.current_action_index >= len(self.current_plan):\n            self.executing = False\n            self.publish_status("Plan complete")\n            return\n        \n        action = self.current_plan[self.current_action_index]\n        action_name = action.get(\'action\')\n        parameters = action.get(\'parameters\', {})\n        \n        self.get_logger().info(f\'Executing action {self.current_action_index + 1}/{len(self.current_plan)}: {action_name}\')\n        self.publish_status(f"Executing: {action_name}")\n        \n        # Map action to ROS 2 Action\n        if action_name == \'navigate_to\':\n            self.execute_navigate(parameters)\n        elif action_name == \'pick_up\':\n            self.execute_pick_up(parameters)\n        elif action_name == \'place\':\n            self.execute_place(parameters)\n        elif action_name == \'look_at\':\n            self.execute_look_at(parameters)\n        elif action_name == \'speak\':\n            self.execute_speak(parameters)\n        elif action_name == \'wait\':\n            self.execute_wait(parameters)\n        else:\n            self.get_logger().error(f\'Unknown action: {action_name}\')\n            self.handle_action_error(action_name, f"Unknown action: {action_name}")\n    \n    def execute_navigate(self, parameters):\n        """Execute navigation action"""\n        location = parameters.get(\'location\')\n        \n        if location not in self.location_map:\n            self.get_logger().error(f\'Unknown location: {location}\')\n            self.handle_action_error(\'navigate_to\', f"Unknown location: {location}")\n            return\n        \n        # Wait for action server\n        if not self.nav_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\'Navigation action server not available\')\n            self.handle_action_error(\'navigate_to\', "Action server not available")\n            return\n        \n        # Create goal\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose.header.frame_id = \'map\'\n        goal_msg.pose.header.stamp = self.get_clock().now().to_msg()\n        \n        loc = self.location_map[location]\n        goal_msg.pose.pose.position.x = loc[\'x\']\n        goal_msg.pose.pose.position.y = loc[\'y\']\n        goal_msg.pose.pose.position.z = 0.0\n        \n        # Convert theta to quaternion\n        q = self.euler_to_quaternion(0, 0, loc[\'theta\'])\n        goal_msg.pose.pose.orientation = q\n        \n        # Send goal\n        self.send_goal_future = self.nav_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.nav_feedback_callback\n        )\n        self.send_goal_future.add_done_callback(self.nav_goal_response_callback)\n    \n    def execute_pick_up(self, parameters):\n        """Execute pick up action"""\n        object_id = parameters.get(\'object\')\n        \n        if not CUSTOM_ACTIONS_AVAILABLE:\n            self.get_logger().warn(\'PickObject action not available, simulating...\')\n            # Simulate action\n            self.get_clock().create_timer(2.0, lambda: self.action_complete(\'pick_up\', {"object": object_id}))\n            return\n        \n        if not self.pick_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\'PickObject action server not available\')\n            self.handle_action_error(\'pick_up\', "Action server not available")\n            return\n        \n        # Get object pose (would query vision system in production)\n        object_pose = self.get_object_pose(object_id)\n        if not object_pose:\n            self.handle_action_error(\'pick_up\', f"Object not found: {object_id}")\n            return\n        \n        # Create goal\n        goal_msg = PickObject.Goal()\n        goal_msg.object_id = object_id\n        goal_msg.object_pose = object_pose\n        \n        # Send goal\n        self.send_goal_future = self.pick_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.pick_feedback_callback\n        )\n        self.send_goal_future.add_done_callback(self.pick_goal_response_callback)\n    \n    def execute_place(self, parameters):\n        """Execute place action"""\n        object_id = parameters.get(\'object\')\n        location = parameters.get(\'location\')\n        \n        if not CUSTOM_ACTIONS_AVAILABLE:\n            self.get_logger().warn(\'PlaceObject action not available, simulating...\')\n            self.get_clock().create_timer(2.0, lambda: self.action_complete(\'place\', {"object": object_id, "location": location}))\n            return\n        \n        if not self.place_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\'PlaceObject action server not available\')\n            self.handle_action_error(\'place\', "Action server not available")\n            return\n        \n        # Get target pose\n        if location in self.location_map:\n            target_pose = self.create_pose_stamped(location)\n        else:\n            self.handle_action_error(\'place\', f"Unknown location: {location}")\n            return\n        \n        # Create goal\n        goal_msg = PlaceObject.Goal()\n        goal_msg.object_id = object_id\n        goal_msg.target_pose = target_pose\n        \n        # Send goal\n        self.send_goal_future = self.place_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.place_feedback_callback\n        )\n        self.send_goal_future.add_done_callback(self.place_goal_response_callback)\n    \n    def execute_look_at(self, parameters):\n        """Execute look at action (simplified)"""\n        object_id = parameters.get(\'object\')\n        self.get_logger().info(f\'Looking at: {object_id}\')\n        # In production: Control camera/head to look at object\n        # For now: Simulate\n        self.action_complete(\'look_at\', {"object": object_id})\n    \n    def execute_speak(self, parameters):\n        """Execute speak action"""\n        text = parameters.get(\'text\', \'\')\n        self.get_logger().info(f\'Robot says: {text}\')\n        # In production: Use TTS (text-to-speech) system\n        # For now: Log message\n        self.action_complete(\'speak\', {"text": text})\n    \n    def execute_wait(self, parameters):\n        """Execute wait action"""\n        duration = parameters.get(\'duration\', 1.0)\n        self.get_logger().info(f\'Waiting for {duration} seconds\')\n        # Create timer for wait\n        self.get_clock().create_timer(duration, lambda: self.action_complete(\'wait\', {"duration": duration}))\n    \n    # Action response callbacks\n    def nav_goal_response_callback(self, future):\n        """Handle navigation goal response"""\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.get_logger().error(\'Navigation goal rejected\')\n            self.handle_action_error(\'navigate_to\', "Goal rejected")\n            return\n        \n        self.get_logger().info(\'Navigation goal accepted\')\n        result_future = goal_handle.get_result_async()\n        result_future.add_done_callback(self.nav_result_callback)\n    \n    def nav_feedback_callback(self, feedback_msg):\n        """Handle navigation feedback"""\n        feedback = feedback_msg.feedback\n        self.get_logger().info(f\'Navigation progress: {feedback.current_pose.pose.position}\')\n    \n    def nav_result_callback(self, future):\n        """Handle navigation result"""\n        result = future.result().result\n        if result:\n            self.get_logger().info(\'Navigation completed successfully\')\n            self.action_complete(\'navigate_to\', {"location": "target"})\n        else:\n            self.handle_action_error(\'navigate_to\', "Navigation failed")\n    \n    def pick_goal_response_callback(self, future):\n        """Handle pick goal response"""\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.handle_action_error(\'pick_up\', "Goal rejected")\n            return\n        result_future = goal_handle.get_result_async()\n        result_future.add_done_callback(self.pick_result_callback)\n    \n    def pick_feedback_callback(self, feedback_msg):\n        """Handle pick feedback"""\n        feedback = feedback_msg.feedback\n        self.get_logger().info(f\'Pick progress: {feedback.progress:.2f}\')\n    \n    def pick_result_callback(self, future):\n        """Handle pick result"""\n        result = future.result().result\n        if result.success:\n            self.action_complete(\'pick_up\', {"object": "target"})\n        else:\n            self.handle_action_error(\'pick_up\', result.message)\n    \n    def place_goal_response_callback(self, future):\n        """Handle place goal response"""\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.handle_action_error(\'place\', "Goal rejected")\n            return\n        result_future = goal_handle.get_result_async()\n        result_future.add_done_callback(self.place_result_callback)\n    \n    def place_feedback_callback(self, feedback_msg):\n        """Handle place feedback"""\n        feedback = feedback_msg.feedback\n        self.get_logger().info(f\'Place progress: {feedback.progress:.2f}\')\n    \n    def place_result_callback(self, future):\n        """Handle place result"""\n        result = future.result().result\n        if result.success:\n            self.action_complete(\'place\', {"object": "target", "location": "target"})\n        else:\n            self.handle_action_error(\'place\', result.message)\n    \n    def action_complete(self, action_name, result_data):\n        """Handle action completion"""\n        self.get_logger().info(f\'Action completed: {action_name}\')\n        \n        # Publish completion\n        complete_msg = String()\n        complete_msg.data = json.dumps({\n            "action": action_name,\n            "result": result_data\n        })\n        self.complete_pub.publish(complete_msg)\n        \n        # Move to next action\n        self.current_action_index += 1\n        self.execute_next_action()\n    \n    def handle_action_error(self, action_name, error_message):\n        """Handle action failure"""\n        self.get_logger().error(f\'Action failed: {action_name} - {error_message}\')\n        \n        # Publish error\n        error_msg = String()\n        error_msg.data = json.dumps({\n            "action": action_name,\n            "error": error_message,\n            "original_command": "unknown"  # Would track original command\n        })\n        self.error_pub.publish(error_msg)\n        \n        # Stop execution (or trigger replanning)\n        self.executing = False\n        self.publish_status("Execution failed")\n    \n    def publish_status(self, status):\n        """Publish execution status"""\n        msg = String()\n        msg.data = status\n        self.status_pub.publish(msg)\n    \n    # Helper functions\n    def euler_to_quaternion(self, roll, pitch, yaw):\n        """Convert Euler angles to quaternion"""\n        qx = math.sin(roll/2) * math.cos(pitch/2) * math.cos(yaw/2) - math.cos(roll/2) * math.sin(pitch/2) * math.sin(yaw/2)\n        qy = math.cos(roll/2) * math.sin(pitch/2) * math.cos(yaw/2) + math.sin(roll/2) * math.cos(pitch/2) * math.sin(yaw/2)\n        qz = math.cos(roll/2) * math.cos(pitch/2) * math.sin(yaw/2) - math.sin(roll/2) * math.sin(pitch/2) * math.cos(yaw/2)\n        qw = math.cos(roll/2) * math.cos(pitch/2) * math.cos(yaw/2) + math.sin(roll/2) * math.sin(pitch/2) * math.sin(yaw/2)\n        \n        q = Quaternion()\n        q.x = qx\n        q.y = qy\n        q.z = qz\n        q.w = qw\n        return q\n    \n    def get_object_pose(self, object_id):\n        """Get object pose (would query vision system)"""\n        # Placeholder - in production: Query vision/VSLAM for object pose\n        pose = PoseStamped()\n        pose.header.frame_id = \'map\'\n        pose.header.stamp = self.get_clock().now().to_msg()\n        pose.pose.position.x = 2.0\n        pose.pose.position.y = 1.0\n        pose.pose.position.z = 0.5\n        pose.pose.orientation.w = 1.0\n        return pose\n    \n    def create_pose_stamped(self, location):\n        """Create pose from location name"""\n        if location not in self.location_map:\n            return None\n        loc = self.location_map[location]\n        pose = PoseStamped()\n        pose.header.frame_id = \'map\'\n        pose.header.stamp = self.get_clock().now().to_msg()\n        pose.pose.position.x = loc[\'x\']\n        pose.pose.position.y = loc[\'y\']\n        pose.pose.position.z = 0.0\n        pose.pose.orientation = self.euler_to_quaternion(0, 0, loc[\'theta\'])\n        return pose\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = ActionExecutor()\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Add to setup.py"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"entry_points={\n    'console_scripts': [\n        'whisper_node = voice_commands.whisper_node:main',\n        'command_processor = voice_commands.command_processor:main',\n        'llm_planner = voice_commands.llm_planner:main',\n        'action_executor = voice_commands.action_executor:main',\n    ],\n},\n"})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-test-action-execution",children:"Step 3: Test Action Execution"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Launch complete pipeline"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Terminal 1: Whisper\nros2 run voice_commands whisper_node\n\n# Terminal 2: Command processor\nros2 run voice_commands command_processor\n\n# Terminal 3: LLM planner\nros2 run voice_commands llm_planner\n\n# Terminal 4: Action executor\nros2 run voice_commands action_executor\n\n# Terminal 5: Nav2 (if available)\nros2 launch nav2_bringup navigation_launch.py\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Test end-to-end"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:'Say: "Pick up the red cup and place it on the table"'}),"\n",(0,s.jsxs)(n.li,{children:["Watch execution:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Whisper transcribes"}),"\n",(0,s.jsx)(n.li,{children:"LLM generates plan"}),"\n",(0,s.jsx)(n.li,{children:"Action executor executes actions"}),"\n",(0,s.jsx)(n.li,{children:"Status updates published"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Monitor topics"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /voice_commands/execution_status\nros2 topic echo /voice_commands/action_complete\nros2 topic echo /voice_commands/action_error\n"})}),"\n",(0,s.jsx)(n.h3,{id:"step-4-precondition-checking",children:"Step 4: Precondition Checking"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Add precondition validation"}),": ",(0,s.jsx)(n.code,{children:"voice_commands/precondition_checker.py"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nCheck action preconditions before execution\n"""\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nimport json\n\nclass PreconditionChecker(Node):\n    def __init__(self):\n        super().__init__(\'precondition_checker\')\n        \n        # Subscribe to plans\n        self.plan_sub = self.create_subscription(\n            String,\n            \'/voice_commands/plan\',\n            self.plan_callback,\n            10\n        )\n        \n        # Publisher for validated plans\n        self.validated_plan_pub = self.create_publisher(String, \'/voice_commands/validated_plan\', 10)\n        \n        # Robot state (would subscribe to actual state topics)\n        self.robot_state = {\n            "location": "living_room",\n            "held_object": None,\n            "battery_level": 100.0,\n        }\n    \n    def plan_callback(self, msg):\n        """Validate plan preconditions"""\n        plan = json.loads(msg.data)\n        validated_plan = []\n        \n        for action in plan:\n            action_name = action.get(\'action\')\n            parameters = action.get(\'parameters\', {})\n            \n            # Check preconditions\n            if self.check_preconditions(action_name, parameters):\n                validated_plan.append(action)\n            else:\n                self.get_logger().warn(f\'Action failed precondition check: {action_name}\')\n                # Could request replanning here\n        \n        # Publish validated plan\n        if validated_plan:\n            msg = String()\n            msg.data = json.dumps(validated_plan)\n            self.validated_plan_pub.publish(msg)\n    \n    def check_preconditions(self, action_name, parameters):\n        """Check if action preconditions are met"""\n        if action_name == \'pick_up\':\n            # Precondition: Robot must be near object\n            object_id = parameters.get(\'object\')\n            # Check if object exists and is reachable\n            return self.object_exists(object_id) and self.object_reachable(object_id)\n        \n        elif action_name == \'place\':\n            # Precondition: Robot must be holding object\n            object_id = parameters.get(\'object\')\n            return self.robot_state[\'held_object\'] == object_id\n        \n        elif action_name == \'navigate_to\':\n            # Precondition: Battery sufficient\n            return self.robot_state[\'battery_level\'] > 20.0\n        \n        return True  # Default: allow action\n    \n    def object_exists(self, object_id):\n        """Check if object exists (would query vision system)"""\n        # Placeholder\n        return True\n    \n    def object_reachable(self, object_id):\n        """Check if object is within reach (would check kinematics)"""\n        # Placeholder\n        return True\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-5-debugging-common-issues",children:"Step 5: Debugging Common Issues"}),"\n",(0,s.jsx)(n.h4,{id:"issue-1-action-server-not-available",children:'Issue 1: "Action server not available"'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Symptoms"}),": Action client can't connect to server"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Check if action server is running\nros2 action list\n\n# Verify action server node\nros2 node list | grep [action_server_name]\n\n# Check action server is in same ROS domain\necho $ROS_DOMAIN_ID\n"})}),"\n",(0,s.jsx)(n.h4,{id:"issue-2-action-goal-rejected",children:'Issue 2: "Action goal rejected"'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Symptoms"}),": Action server rejects goal"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Check goal format\n# Verify goal message structure matches action definition\n# Check goal parameters are valid (e.g., pose in valid range)\n\n# Add goal validation\ndef validate_goal(self, goal_msg):\n    # Check pose is in map bounds\n    # Check object exists\n    # Check robot can reach\n    pass\n"})}),"\n",(0,s.jsx)(n.h4,{id:"issue-3-action-execution-hangs",children:'Issue 3: "Action execution hangs"'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Symptoms"}),": Action never completes"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Add timeout\nimport asyncio\n\nasync def execute_with_timeout(self, action_func, timeout=30.0):\n    try:\n        await asyncio.wait_for(action_func(), timeout=timeout)\n    except asyncio.TimeoutError:\n        self.get_logger().error('Action timeout')\n        self.handle_action_error(action_name, \"Timeout\")\n"})}),"\n",(0,s.jsx)(n.h4,{id:"issue-4-actions-execute-out-of-order",children:'Issue 4: "Actions execute out of order"'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Symptoms"}),": Actions don't wait for previous action to complete"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Ensure sequential execution\n# Don't call execute_next_action() until current action completes\n# Use callbacks properly (don't call next action in send_goal, wait for result)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"part-3-advanced-topics-optional",children:"Part 3: Advanced Topics (Optional)"}),"\n",(0,s.jsx)(n.h3,{id:"parallel-action-execution",children:"Parallel Action Execution"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Execute independent actions in parallel"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Some actions can run in parallel (e.g., look_at while navigating)\n# Use asyncio or threading for parallel execution\n# But ensure dependencies are respected\n"})}),"\n",(0,s.jsx)(n.h3,{id:"action-retry-logic",children:"Action Retry Logic"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Retry failed actions"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def execute_with_retry(self, action_func, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            result = action_func()\n            if result.success:\n                return result\n        except Exception as e:\n            if attempt == max_retries - 1:\n                raise\n            self.get_logger().warn(f'Action failed, retrying ({attempt + 1}/{max_retries})')\n"})}),"\n",(0,s.jsx)(n.h2,{id:"integration-with-capstone",children:"Integration with Capstone"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"How this chapter contributes"})," to the Week 13 autonomous humanoid:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Action execution"}),": Capstone will execute LLM plans via ROS 2 Actions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Robustness"}),": Precondition checking and error handling ensure reliable execution"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Feedback"}),": Action completion feedback enables replanning"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Integration"}),": Connects LLM planning to robot control"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Understanding action execution now is essential for the capstone system."}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"You learned:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\u2705 Mapped ",(0,s.jsx)(n.strong,{children:"natural language actions"})," to ROS 2 Action goals"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 Implemented ",(0,s.jsx)(n.strong,{children:"action executor"})," coordinating multiple behaviors"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 Handled ",(0,s.jsx)(n.strong,{children:"preconditions and postconditions"})," for robust execution"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 Created ",(0,s.jsx)(n.strong,{children:"feedback mechanisms"})," for action completion"]}),"\n",(0,s.jsxs)(n.li,{children:["\u2705 Debugged ",(0,s.jsx)(n.strong,{children:"action execution failures"})," and recovery"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Next steps"}),": In Chapter 4.4, you'll integrate multi-modal inputs (speech + vision + gesture) for richer human-robot interaction."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,s.jsx)(n.h3,{id:"exercise-1-basic-action-execution-required",children:"Exercise 1: Basic Action Execution (Required)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Objective"}),": Execute simple action plans via ROS 2 Actions."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Create action executor node"}),"\n",(0,s.jsx)(n.li,{children:"Implement navigation action execution"}),"\n",(0,s.jsxs)(n.li,{children:["Test with simple plan: ",(0,s.jsx)(n.code,{children:'[{"action": "navigate_to", "parameters": {"location": "kitchen"}}]'})]}),"\n",(0,s.jsx)(n.li,{children:"Verify action completes successfully"}),"\n",(0,s.jsx)(n.li,{children:"Monitor action feedback and results"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Acceptance Criteria"}),":"]}),"\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Action executor node running"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Navigation action executes correctly"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Action completion published"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Feedback received during execution"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Estimated Time"}),": 120 minutes"]}),"\n",(0,s.jsx)(n.h3,{id:"exercise-2-precondition-checking-required",children:"Exercise 2: Precondition Checking (Required)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Objective"}),": Validate action preconditions before execution."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Create precondition checker node"}),"\n",(0,s.jsx)(n.li,{children:"Define preconditions for each action type"}),"\n",(0,s.jsx)(n.li,{children:"Validate plans before execution"}),"\n",(0,s.jsx)(n.li,{children:"Test with invalid plans (should be filtered)"}),"\n",(0,s.jsx)(n.li,{children:"Document precondition rules"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Acceptance Criteria"}),":"]}),"\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Precondition checker implemented"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Invalid actions filtered out"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Valid plans pass through"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Precondition rules documented"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Estimated Time"}),": 90 minutes"]}),"\n",(0,s.jsx)(n.h3,{id:"exercise-3-error-recovery-challenge",children:"Exercise 3: Error Recovery (Challenge)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Objective"}),": Implement robust error handling and recovery."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Tasks"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Detect action failures"}),"\n",(0,s.jsx)(n.li,{children:"Implement retry logic (3 attempts)"}),"\n",(0,s.jsx)(n.li,{children:"Trigger replanning on persistent failures"}),"\n",(0,s.jsx)(n.li,{children:"Test with simulated failures"}),"\n",(0,s.jsx)(n.li,{children:"Document recovery strategies"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Requirements"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Retry logic implemented"}),"\n",(0,s.jsx)(n.li,{children:"Replanning triggered on failure"}),"\n",(0,s.jsx)(n.li,{children:"Recovery strategies documented"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Estimated Time"}),": 180 minutes"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Intermediate/Writing-an-Action-Server-Client/Py.html",children:"ROS 2 Actions Tutorial"})," - Action implementation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://navigation.ros.org/plugin_tutorials/docs/writing_new_nav2action_plugin.html",children:"Nav2 Actions"})," - Navigation actions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://docs.ros2.org/humble/api/rclpy/api/rclpy.action.html",children:"Action Client API"})," - rclpy action client"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Next"}),": [Chapter 4.4: Multi-Modal Integration (Speech + Vision + Gesture) \u2192](chapter-4 to 4.md)"]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>c});var i=t(6540);const s={},o=i.createContext(s);function a(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);