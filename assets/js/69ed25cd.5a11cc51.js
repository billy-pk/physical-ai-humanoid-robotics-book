"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[441],{6246:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-1/chapter-1-1","title":"1.1 Fundamentals of Artificial Intelligence","description":"Before diving into Physical AI and humanoid robotics, we must build a solid foundation in artificial intelligence itself. This chapter explores core AI concepts, learning paradigms, and the evolution from narrow to general intelligence\u2014all essential for understanding how AI powers physical systems.","source":"@site/docs/module-1/chapter-1-1.md","sourceDirName":"module-1","slug":"/module-1/chapter-1-1","permalink":"/physical-ai-humanoid-robotics-book/docs/module-1/chapter-1-1","draft":false,"unlisted":false,"editUrl":"https://github.com/billy-pk/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module-1/chapter-1-1.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"1.1 Fundamentals of Artificial Intelligence"},"sidebar":"defaultSidebar","previous":{"title":"Introduction to Physical AI and Humanoid Robotics","permalink":"/physical-ai-humanoid-robotics-book/docs/intro"},"next":{"title":"1.2 Robotics Fundamentals","permalink":"/physical-ai-humanoid-robotics-book/docs/module-1/chapter-1-2"}}');var r=i(4848),l=i(8453);const t={sidebar_position:1,title:"1.1 Fundamentals of Artificial Intelligence"},a="Chapter 1.1: Fundamentals of Artificial Intelligence",o={},c=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"What is Artificial Intelligence?",id:"what-is-artificial-intelligence",level:2},{value:"Intelligence Spectrum",id:"intelligence-spectrum",level:3},{value:"Core AI Paradigms",id:"core-ai-paradigms",level:2},{value:"1. Supervised Learning",id:"1-supervised-learning",level:3},{value:"2. Unsupervised Learning",id:"2-unsupervised-learning",level:3},{value:"3. Reinforcement Learning (RL)",id:"3-reinforcement-learning-rl",level:3},{value:"Neural Networks: The Foundation of Modern AI",id:"neural-networks-the-foundation-of-modern-ai",level:2},{value:"Basic Structure",id:"basic-structure",level:3},{value:"How Neurons Work",id:"how-neurons-work",level:3},{value:"Training Neural Networks",id:"training-neural-networks",level:3},{value:"Deep Learning",id:"deep-learning",level:3},{value:"Key AI Challenges Relevant to Robotics",id:"key-ai-challenges-relevant-to-robotics",level:2},{value:"1. Generalization",id:"1-generalization",level:3},{value:"2. Sample Efficiency",id:"2-sample-efficiency",level:3},{value:"3. Robustness",id:"3-robustness",level:3},{value:"4. Interpretability",id:"4-interpretability",level:3},{value:"From Traditional AI to Physical AI",id:"from-traditional-ai-to-physical-ai",level:2},{value:"Practical Example: AI-Powered Object Detection",id:"practical-example-ai-powered-object-detection",level:2},{value:"Code Example (PyTorch + Pre-trained CNN)",id:"code-example-pytorch--pre-trained-cnn",level:3},{value:"Exercises",id:"exercises",level:2},{value:"1. Conceptual Understanding",id:"1-conceptual-understanding",level:3},{value:"2. Neural Network Math",id:"2-neural-network-math",level:3},{value:"3. Design Challenge",id:"3-design-challenge",level:3},{value:"4. Code Exploration",id:"4-code-exploration",level:3},{value:"5. Critical Thinking",id:"5-critical-thinking",level:3},{value:"6. Research Task",id:"6-research-task",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"chapter-11-fundamentals-of-artificial-intelligence",children:"Chapter 1.1: Fundamentals of Artificial Intelligence"})}),"\n",(0,r.jsx)(n.p,{children:"Before diving into Physical AI and humanoid robotics, we must build a solid foundation in artificial intelligence itself. This chapter explores core AI concepts, learning paradigms, and the evolution from narrow to general intelligence\u2014all essential for understanding how AI powers physical systems."}),"\n",(0,r.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Define"})," artificial intelligence and distinguish between narrow and general AI"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Explain"})," the main learning paradigms: supervised, unsupervised, and reinforcement learning"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Understand"})," neural networks and deep learning fundamentals"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Identify"})," key challenges in AI: generalization, sample efficiency, and robustness"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Connect"})," traditional AI concepts to physical robotics applications"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"what-is-artificial-intelligence",children:"What is Artificial Intelligence?"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Artificial Intelligence (AI)"})," is the field of computer science focused on creating systems that can perform tasks typically requiring human intelligence. These tasks include:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Perception"}),": Understanding visual, auditory, or tactile information"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reasoning"}),": Logical thinking, planning, and problem-solving"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Learning"}),": Improving performance through experience"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Language Understanding"}),": Processing and generating natural language"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Decision-Making"}),": Choosing optimal actions in complex situations"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"intelligence-spectrum",children:"Intelligence Spectrum"}),"\n",(0,r.jsx)(n.p,{children:"AI systems exist on a spectrum from narrow to general intelligence:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Examples"}),(0,r.jsx)(n.th,{children:"Status"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Narrow AI (ANI)"})}),(0,r.jsx)(n.td,{children:"Specialized for specific tasks; no general understanding"}),(0,r.jsx)(n.td,{children:"Chess engines, image classifiers, chatbots"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Current state"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"General AI (AGI)"})}),(0,r.jsx)(n.td,{children:"Human-level intelligence across diverse domains"}),(0,r.jsx)(n.td,{children:"Hypothetical systems that can learn any intellectual task"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Future goal"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Super AI (ASI)"})}),(0,r.jsx)(n.td,{children:"Surpasses human intelligence in all domains"}),(0,r.jsx)(n.td,{children:"Speculative; theoretical endpoint"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Far future"})})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:["Currently, all real-world AI\u2014including robotics\u2014falls under ",(0,r.jsx)(n.strong,{children:"Narrow AI"}),". Each system excels at specific tasks but lacks the flexible, transferable intelligence humans possess."]}),"\n",(0,r.jsx)(n.h2,{id:"core-ai-paradigms",children:"Core AI Paradigms"}),"\n",(0,r.jsx)(n.p,{children:"AI systems learn and make decisions using different approaches. The three foundational learning paradigms are:"}),"\n",(0,r.jsx)(n.h3,{id:"1-supervised-learning",children:"1. Supervised Learning"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Definition"}),": Learning from labeled examples where the correct output is provided."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"How it works"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Provide training data: input-output pairs (X, Y)"}),"\n",(0,r.jsx)(n.li,{children:"Algorithm learns a function f(X) \u2192 Y"}),"\n",(0,r.jsx)(n.li,{children:"Minimize prediction error on training data"}),"\n",(0,r.jsx)(n.li,{children:"Generalize to new, unseen inputs"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example - Image Classification"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Training data: images of robots with labels\n# Input (X): Image of robot\n# Output (Y): Category label ("humanoid", "wheeled", "quadruped")\n\n# Supervised learning algorithm learns:\n# f(image) \u2192 category\n\n# After training, can classify new robot images\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robotics Applications"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Object Recognition"}),": Identifying tools, obstacles, or target objects"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pose Estimation"}),": Determining robot's position from sensor data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Grasp Success Prediction"}),": Estimating if a grasp will succeed"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Limitations"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Requires large labeled datasets (expensive to create)"}),"\n",(0,r.jsx)(n.li,{children:"Doesn't handle novel situations well"}),"\n",(0,r.jsx)(n.li,{children:"Limited to problems with clear input-output relationships"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-unsupervised-learning",children:"2. Unsupervised Learning"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Definition"}),": Finding patterns in data ",(0,r.jsx)(n.strong,{children:"without labels"})," or explicit guidance."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"How it works"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Provide unlabeled data (only X, no Y)"}),"\n",(0,r.jsx)(n.li,{children:"Algorithm discovers structure, patterns, or groupings"}),"\n",(0,r.jsx)(n.li,{children:"Common techniques: clustering, dimensionality reduction, anomaly detection"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example - Sensor Data Clustering"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Robot collects sensor data during navigation\n# Algorithm clusters similar environments:\n# - Cluster 1: Indoor, flat surfaces\n# - Cluster 2: Outdoor, rough terrain\n# - Cluster 3: Staircases\n\n# Helps robot adapt behavior to environment type\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robotics Applications"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Environment Mapping"}),": Discovering spatial structure from sensor data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Anomaly Detection"}),": Identifying unusual sensor readings (potential faults)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Feature Learning"}),": Extracting useful representations from raw data"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Limitations"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Patterns may not align with task objectives"}),"\n",(0,r.jsx)(n.li,{children:"Difficult to evaluate quality of learning"}),"\n",(0,r.jsx)(n.li,{children:"Requires domain knowledge to interpret results"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"3-reinforcement-learning-rl",children:"3. Reinforcement Learning (RL)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Definition"}),": Learning through ",(0,r.jsx)(n.strong,{children:"trial and error"})," by interacting with an environment and receiving rewards or penalties."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"How it works"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Agent takes actions in environment"}),"\n",(0,r.jsx)(n.li,{children:"Environment returns new state and reward signal"}),"\n",(0,r.jsx)(n.li,{children:"Agent learns policy (action strategy) to maximize cumulative reward"}),"\n",(0,r.jsx)(n.li,{children:"Explores different actions to find optimal behavior"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Concepts"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Agent"}),": The learning system (e.g., robot)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Environment"}),": The world the agent interacts with"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"State (s)"}),": Current situation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Action (a)"}),": What the agent can do"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reward (r)"}),": Feedback signal (positive or negative)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Policy (\u03c0)"}),": Strategy mapping states to actions"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example - Robot Walking"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Reinforcement Learning for Bipedal Walking\n\n# State: Joint angles, velocities, orientation\n# Actions: Motor torques for each joint\n# Reward:\n#   +1 for each forward step\n#   -10 for falling\n#   -0.1 for excessive energy use\n\n# Over time, robot learns stable, efficient walking policy\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robotics Applications"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Locomotion"}),": Learning to walk, run, or navigate"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Manipulation"}),": Grasping and object handling"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Task Planning"}),": Multi-step decision-making"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Adaptive Control"}),": Adjusting to changing conditions"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Advantages for Robotics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"No need for labeled training data"}),"\n",(0,r.jsx)(n.li,{children:"Can discover novel, creative solutions"}),"\n",(0,r.jsx)(n.li,{children:"Naturally handles sequential decision-making"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Limitations"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Requires many trial-and-error attempts (sample inefficient)"}),"\n",(0,r.jsx)(n.li,{children:"Reward design is critical and challenging"}),"\n",(0,r.jsx)(n.li,{children:"Safety concerns during exploration (robots can break things!)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"neural-networks-the-foundation-of-modern-ai",children:"Neural Networks: The Foundation of Modern AI"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Neural networks"}),' are computational models inspired by biological brains, composed of interconnected "neurons" that process information.']}),"\n",(0,r.jsx)(n.h3,{id:"basic-structure",children:"Basic Structure"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Input Layer \u2192 Hidden Layers \u2192 Output Layer\n\nExample: Robot Obstacle Detection\n\nInput: Camera pixels (RGB values)\n       \u2193\nHidden Layer 1: Edge detection\n       \u2193\nHidden Layer 2: Shape recognition\n       \u2193\nHidden Layer 3: Object classification\n       \u2193\nOutput: Probability of obstacle (0-1)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"how-neurons-work",children:"How Neurons Work"}),"\n",(0,r.jsx)(n.p,{children:"Each artificial neuron:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Receives inputs (x\u2081, x\u2082, ..., x\u2099)"}),"\n",(0,r.jsx)(n.li,{children:"Applies weights (w\u2081, w\u2082, ..., w\u2099)"}),"\n",(0,r.jsx)(n.li,{children:"Sums weighted inputs: z = w\u2081x\u2081 + w\u2082x\u2082 + ... + w\u2099x\u2099 + b (bias)"}),"\n",(0,r.jsx)(n.li,{children:"Passes through activation function: y = f(z)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Common Activation Functions"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ReLU"})," (Rectified Linear Unit): f(z) = max(0, z) \u2014 most common in deep learning"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sigmoid"}),": f(z) = 1/(1 + e\u207b\u1dbb) \u2014 outputs between 0 and 1"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tanh"}),": f(z) = (e\u1dbb - e\u207b\u1dbb)/(e\u1dbb + e\u207b\u1dbb) \u2014 outputs between -1 and 1"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"training-neural-networks",children:"Training Neural Networks"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Backpropagation Algorithm"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Forward pass"}),": Input data flows through network to produce prediction"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compute loss"}),": Measure error between prediction and target"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Backward pass"}),": Calculate gradients (how to change weights to reduce error)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Update weights"}),": Adjust using gradient descent: w \u2190 w - \u03b1\xb7\u2207L (\u03b1 = learning rate)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Repeat"})," for many iterations until convergence"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"deep-learning",children:"Deep Learning"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Deep learning"})," uses neural networks with many layers (10s to 100s) to learn hierarchical representations:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Layer 1"}),": Low-level features (edges, textures)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Layer 2"}),": Mid-level features (shapes, parts)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Layer 3"}),": High-level features (objects, concepts)"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Why Deep Learning Revolutionized AI"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Automatically learns features (no manual engineering needed)"}),"\n",(0,r.jsx)(n.li,{children:"Scales with data (more data \u2192 better performance)"}),"\n",(0,r.jsx)(n.li,{children:"Achieves human-level performance in many perception tasks"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Deep Learning Architectures for Robotics"}),":"]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Architecture"}),(0,r.jsx)(n.th,{children:"Use Case"}),(0,r.jsx)(n.th,{children:"Example Application"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Convolutional Neural Networks (CNNs)"})}),(0,r.jsx)(n.td,{children:"Image/video processing"}),(0,r.jsx)(n.td,{children:"Object detection, scene understanding"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Recurrent Neural Networks (RNNs)"})}),(0,r.jsx)(n.td,{children:"Sequential data"}),(0,r.jsx)(n.td,{children:"Trajectory prediction, time-series analysis"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Transformers"})}),(0,r.jsx)(n.td,{children:"Long-range dependencies"}),(0,r.jsx)(n.td,{children:"Language understanding, multi-modal reasoning"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Graph Neural Networks (GNNs)"})}),(0,r.jsx)(n.td,{children:"Structured relationships"}),(0,r.jsx)(n.td,{children:"Robot morphology, scene graphs"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"key-ai-challenges-relevant-to-robotics",children:"Key AI Challenges Relevant to Robotics"}),"\n",(0,r.jsx)(n.h3,{id:"1-generalization",children:"1. Generalization"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Problem"}),": AI systems often fail on examples slightly different from training data."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robotics Impact"}),": A robot trained to grasp red cups may fail with blue cups or slightly different shapes."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Data augmentation (vary training examples)"}),"\n",(0,r.jsx)(n.li,{children:"Domain randomization (train in diverse simulated environments)"}),"\n",(0,r.jsx)(n.li,{children:"Meta-learning (learning to learn across tasks)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-sample-efficiency",children:"2. Sample Efficiency"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Problem"}),": Deep learning requires massive datasets (millions of examples)."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robotics Impact"}),": Collecting real-world robot data is slow and expensive."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Simulation-based training (sim-to-real transfer)"}),"\n",(0,r.jsx)(n.li,{children:"Transfer learning (use pre-trained models)"}),"\n",(0,r.jsx)(n.li,{children:"Few-shot learning (learn from few examples)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"3-robustness",children:"3. Robustness"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Problem"}),": AI systems can be fragile to noise, adversarial examples, or distribution shifts."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robotics Impact"}),": Lighting changes, worn sensors, or novel obstacles can cause failures."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Adversarial training"}),"\n",(0,r.jsx)(n.li,{children:"Uncertainty estimation"}),"\n",(0,r.jsx)(n.li,{children:"Sensor fusion (combine multiple data sources)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"4-interpretability",children:"4. Interpretability"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Problem"}),': Deep neural networks are "black boxes" \u2014 hard to understand why they make decisions.']}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robotics Impact"}),": Critical for safety, debugging, and trust in human-robot collaboration."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Attention visualization"}),"\n",(0,r.jsx)(n.li,{children:"Explainable AI (XAI) methods"}),"\n",(0,r.jsx)(n.li,{children:"Hybrid approaches (symbolic + neural)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"from-traditional-ai-to-physical-ai",children:"From Traditional AI to Physical AI"}),"\n",(0,r.jsxs)(n.p,{children:["Traditional AI focuses on digital tasks (classification, prediction, language), while ",(0,r.jsx)(n.strong,{children:"Physical AI"})," adds unique constraints:"]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Aspect"}),(0,r.jsx)(n.th,{children:"Traditional AI"}),(0,r.jsx)(n.th,{children:"Physical AI"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Environment"})}),(0,r.jsx)(n.td,{children:"Digital, predictable"}),(0,r.jsx)(n.td,{children:"Physical, unpredictable"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Feedback"})}),(0,r.jsx)(n.td,{children:"Instant, precise"}),(0,r.jsx)(n.td,{children:"Delayed, noisy"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Safety"})}),(0,r.jsx)(n.td,{children:"Low stakes (software errors)"}),(0,r.jsx)(n.td,{children:"High stakes (hardware damage, human harm)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Embodiment"})}),(0,r.jsx)(n.td,{children:"None"}),(0,r.jsx)(n.td,{children:"Must respect physics, kinematics"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Real-time"})}),(0,r.jsx)(n.td,{children:"Often offline processing"}),(0,r.jsx)(n.td,{children:"Must react in milliseconds"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Implications"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sim-to-Real Gap"}),": Models trained in simulation may fail on real robots due to unmodeled physics."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Safety Constraints"}),": Exploration must avoid dangerous actions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Partial Observability"}),": Sensors provide incomplete, noisy information."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-objective Optimization"}),": Must balance performance, energy, safety, wear."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"practical-example-ai-powered-object-detection",children:"Practical Example: AI-Powered Object Detection"}),"\n",(0,r.jsx)(n.p,{children:"Let's see how AI enables a humanoid robot to detect objects in its environment."}),"\n",(0,r.jsx)(n.h3,{id:"code-example-pytorch--pre-trained-cnn",children:"Code Example (PyTorch + Pre-trained CNN)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import torch\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet50\nfrom PIL import Image\n\n# Load pre-trained ResNet50 model\nmodel = resnet50(pretrained=True)\nmodel.eval()  # Set to evaluation mode\n\n# Image preprocessing\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                       std=[0.229, 0.224, 0.225])\n])\n\ndef detect_object(image_path):\n    """\n    Detect object in image using pre-trained CNN.\n\n    Args:\n        image_path: Path to input image\n\n    Returns:\n        Predicted class label\n    """\n    # Load and preprocess image\n    image = Image.open(image_path)\n    input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n\n    # Forward pass\n    with torch.no_grad():\n        output = model(input_tensor)\n\n    # Get predicted class (highest probability)\n    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n    predicted_class = torch.argmax(probabilities).item()\n    confidence = probabilities[predicted_class].item()\n\n    # Load ImageNet class labels\n    with open("imagenet_classes.txt") as f:\n        classes = [line.strip() for line in f.readlines()]\n\n    return classes[predicted_class], confidence\n\n# Example usage\nobject_name, confidence = detect_object("robot_camera_view.jpg")\nprint(f"Detected: {object_name} (confidence: {confidence:.2%})")\n\n# Output: Detected: coffee mug (confidence: 94.23%)\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"How This Connects to Robotics"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Robot's camera captures image \u2192 ",(0,r.jsx)(n.code,{children:"robot_camera_view.jpg"})]}),"\n",(0,r.jsx)(n.li,{children:"CNN processes image \u2192 identifies object"}),"\n",(0,r.jsx)(n.li,{children:'Decision system uses detection \u2192 "pick up the coffee mug"'}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsx)(n.h3,{id:"1-conceptual-understanding",children:"1. Conceptual Understanding"}),"\n",(0,r.jsxs)(n.p,{children:["For each learning paradigm, provide a robotics example ",(0,r.jsx)(n.strong,{children:"not mentioned in the chapter"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Supervised learning: ___"}),"\n",(0,r.jsx)(n.li,{children:"Unsupervised learning: ___"}),"\n",(0,r.jsx)(n.li,{children:"Reinforcement learning: ___"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-neural-network-math",children:"2. Neural Network Math"}),"\n",(0,r.jsx)(n.p,{children:"Given a simple neuron with:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Inputs: x\u2081 = 0.5, x\u2082 = -0.3"}),"\n",(0,r.jsx)(n.li,{children:"Weights: w\u2081 = 1.2, w\u2082 = 0.8"}),"\n",(0,r.jsx)(n.li,{children:"Bias: b = -0.1"}),"\n",(0,r.jsx)(n.li,{children:"Activation: ReLU"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Calculate the neuron's output step-by-step."}),"\n",(0,r.jsx)(n.h3,{id:"3-design-challenge",children:"3. Design Challenge"}),"\n",(0,r.jsx)(n.p,{children:"You're building a humanoid robot for warehouse sorting. Design an AI system:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Task"}),": Identify and sort packages by size (small, medium, large)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensors"}),": RGB camera"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Decide"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Which learning paradigm would you use? (justify)"}),"\n",(0,r.jsx)(n.li,{children:"What would be your input and output?"}),"\n",(0,r.jsx)(n.li,{children:"What challenges might you face?"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"4-code-exploration",children:"4. Code Exploration"}),"\n",(0,r.jsx)(n.p,{children:"Modify the object detection code to:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Return the ",(0,r.jsx)(n.strong,{children:"top 3"})," predicted classes instead of just one"]}),"\n",(0,r.jsx)(n.li,{children:"Add a confidence threshold (only return if confidence > 0.8)"}),"\n",(0,r.jsx)(n.li,{children:"Save the prediction results to a log file"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"5-critical-thinking",children:"5. Critical Thinking"}),"\n",(0,r.jsx)(n.p,{children:"Explain why reinforcement learning is challenging for real-world robotics compared to simulated environments like video games. List at least 3 specific challenges."}),"\n",(0,r.jsx)(n.h3,{id:"6-research-task",children:"6. Research Task"}),"\n",(0,r.jsx)(n.p,{children:"Find a recent paper (2023-2024) on AI for robotics. Summarize:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The main AI technique used (supervised, RL, etc.)"}),"\n",(0,r.jsx)(n.li,{children:"The robotics application"}),"\n",(0,r.jsx)(n.li,{children:"Key results or innovations"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(n.p,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"AI"})," is about creating systems that perform tasks requiring intelligence\n\u2705 ",(0,r.jsx)(n.strong,{children:"Three main paradigms"}),": Supervised (labeled data), Unsupervised (find patterns), Reinforcement (trial and error)\n\u2705 ",(0,r.jsx)(n.strong,{children:"Neural networks"})," process information through layers of weighted connections\n\u2705 ",(0,r.jsx)(n.strong,{children:"Deep learning"})," uses many layers to learn hierarchical features automatically\n\u2705 ",(0,r.jsx)(n.strong,{children:"Physical AI"})," faces unique challenges: real-time constraints, safety, sim-to-real gap\n\u2705 Modern robotics relies heavily on ",(0,r.jsx)(n.strong,{children:"deep learning for perception"})," and ",(0,r.jsx)(n.strong,{children:"RL for control"})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Books"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Deep Learning"})," by Goodfellow, Bengio, and Courville (comprehensive DL textbook)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Reinforcement Learning: An Introduction"})," by Sutton and Barto (RL bible)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Artificial Intelligence: A Modern Approach"})," by Russell and Norvig (AI fundamentals)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Online Courses"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Andrew Ng's Machine Learning (Coursera) \u2014 foundational course"}),"\n",(0,r.jsx)(n.li,{children:"CS231n: Convolutional Neural Networks (Stanford) \u2014 computer vision"}),"\n",(0,r.jsx)(n.li,{children:"Deep RL Bootcamp (UC Berkeley) \u2014 reinforcement learning"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Papers"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'"ImageNet Classification with Deep Convolutional Neural Networks" (AlexNet, 2012)'}),"\n",(0,r.jsx)(n.li,{children:'"Mastering the game of Go with deep neural networks" (AlphaGo, 2016)'}),"\n",(0,r.jsx)(n.li,{children:'"Sim-to-Real: Learning Agile Locomotion For Quadruped Robots" (2018)'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Previous"}),": ",(0,r.jsx)(n.a,{href:"/physical-ai-humanoid-robotics-book/docs/intro",children:"\u2190 Introduction"})," | ",(0,r.jsx)(n.strong,{children:"Next"}),": ",(0,r.jsx)(n.a,{href:"/physical-ai-humanoid-robotics-book/docs/module-1/chapter-1-2",children:"Chapter 1.2: Robotics Fundamentals \u2192"})]}),"\n",(0,r.jsx)(n.p,{children:"Ready to connect AI theory to physical systems? The next chapter explores the mechanical and control foundations of robotics!"})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>a});var s=i(6540);const r={},l=s.createContext(r);function t(e){const n=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);